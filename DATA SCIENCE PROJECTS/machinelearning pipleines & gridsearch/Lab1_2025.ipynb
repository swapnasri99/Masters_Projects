{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q12HxMI60d_"
      },
      "source": [
        "# Lab 1: Machine Learning Pipelines and Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "How to Use This Notebook\n",
        "\n",
        "---\n",
        "\n",
        "**Recommended Setup**\n",
        "\n",
        "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
        "\n",
        "- In Colab, **enable GPU support** by going to:  \n",
        "\n",
        "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
        "\n",
        "**Homework Tasks**\n",
        "\n",
        " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > ```Your code ....```\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > *End of Task X.*\n",
        "\n",
        " - For each task:\n",
        "\n",
        "   - **Complete the code** where indicated.\n",
        "\n",
        "   - **Upload the required results** from each task to **Homework 1 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        " - Once you've finished all the tasks:\n",
        "\n",
        "   Submit your **entire completed notebook (including your code!)** to **Homework 1 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        "**Important:**  \n",
        "\n",
        "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8KoF17IqO3GV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3CcFUFw63FV"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "This lab will cover various ensemble learning methods covered in the lectures, such as boosting, bagging, and stacking, together with the scikit-learn pipeline. We will tackle the fetal health classification problem using random forest and XGBoost for better performances. We will also learn how to integrate preprocessing and training processes into one pipeline to re-use the whole process easier. The objective of this lab is to get a concept of a whole machine learning pipeline from feature engineering to model selection and lead to a final model.\n",
        "\n",
        "This lab will mainly focus on:\n",
        "- Learn how to preprocess and oversample imbalanced datasets.\n",
        "- Learn how to use the basic random forest, Adaboost, and XGBoost.\n",
        "- Learn how to use grid search (recap on DAMI) and randomized search.\n",
        "- Learn how to use the scikit-learn pipeline to construct a complete and reusable preprocessing cycle.\n",
        "\n",
        "Our goal is to find out the best ensemble model for our dataset. We need to split the dataset into two parts: training and validation sets. Then we test parameter options and eventually choose one best model and compare their test performance.\n",
        "\n",
        "We will use the [fetal health classification](https://www.kaggle.com/andrewmvd/fetal-health-classification) data from Kaggle. The reduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a crucial indicator of human progress. The UN expects that by 2030, countries end preventable deaths of newborns and children under five years of age, with all countries aiming to reduce under‑5 mortality to at least as low as 25 per 1,000 live births.\n",
        "\n",
        "Parallel to the notion of child mortality is of course maternal mortality, which accounts for 295 000 deaths during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths (94%) occurred in low-resource settings, and most could have been prevented.\n",
        "\n",
        "In light of what was mentioned above, Cardiotocograms (CTGs) are a simple and cost-accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine contractions, and more.\n",
        "\n",
        "This dataset contains 2126 records of features extracted from Cardiotocogram exams, which were then classified by three expert obstetricians into three classes:\n",
        "\n",
        "- Normal: 1\n",
        "- Suspect: 2\n",
        "- Pathological: 3\n",
        "\n",
        "We will first try to apply ensemble models and eventually integrate grid search and pipeline to create an automated evaluation process to find the best model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV9PLTbf042I"
      },
      "source": [
        "### 1. Data exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PORkBQrI3B_t"
      },
      "source": [
        "Let's locate the dataset anywhere you want in your local and load it using pd.read_csv. The dataset can be downloaded [here](https://www.kaggle.com/andrewmvd/fetal-health-classification). This time, we will return to pandas DataFrame!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok5R_kam0POu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imblearn # install if you don't have it\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rga_P0fD0POv"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame\n",
        "data = pd.read_csv(\"fetal_health.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-KDk5y30POv"
      },
      "outputs": [],
      "source": [
        "# head\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFZ-r0aIOI9L"
      },
      "source": [
        "**Duplicates**: The first thing we need to do is to separate features and labels. However, before that, let's check if the data has some duplicated rows."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates in data\n",
        "data.duplicated()"
      ],
      "metadata": {
        "id": "sXbxejEEVUQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTYpHB4D0POv"
      },
      "outputs": [],
      "source": [
        "# How many duplicates\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lTfDJ7q0POv"
      },
      "outputs": [],
      "source": [
        "# drop_duplicates\n",
        "data_dropped = data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dropped datapoints and compare to before dropping duplicates\n",
        "data_dropped"
      ],
      "metadata": {
        "id": "TZPTTpDfXTI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "OusYvIP1XjIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o6GaJIljO8a"
      },
      "source": [
        "**Features/labels split**: We can choose the columns from the dataframe and create a new variable X.\n",
        "- what would be our label?\n",
        "- how could we only choose the columns?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7ormC5y2ygj"
      },
      "outputs": [],
      "source": [
        "# Features\n",
        "X = data_dropped.iloc[:, :-1]\n",
        "# Labels\n",
        "y = data_dropped[\"fetal_health\"].astype(int) # Pandas series shares some functions with NumPy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2ltuneE28a2"
      },
      "outputs": [],
      "source": [
        "# X.head\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aJq-seT29tM"
      },
      "outputs": [],
      "source": [
        "# y.head\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_kvifl82-IS"
      },
      "outputs": [],
      "source": [
        "# describe - Basic statistics\n",
        "X.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP57R2Sn5ZxJ"
      },
      "source": [
        "Today, our focus is to learn about ensemble methods, so we would not focus on many data exploration strategies, but let's try to investigate a few things. First, let's check if the labels are balanced or not using seaborn.\n",
        "- [Useful seaborn functions](https://seaborn.pydata.org/tutorial/function_overview.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WVRAVtZMTJ9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z-EY7ES5Y6A"
      },
      "outputs": [],
      "source": [
        "# countplot - check the proportion visually\n",
        "sns.countplot(x=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgSk35Su6JJn"
      },
      "outputs": [],
      "source": [
        "# series.value counts - check the proportion\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlRW7iZ_M3pM"
      },
      "outputs": [],
      "source": [
        "# proportion\n",
        "y.value_counts() / len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDgtM6oA6Anv"
      },
      "source": [
        "It is natural that the normal cases are most common. It might lead to higher accuracy too, as label 1 keeps about 78% of the whole dataset. However, to make a robust model that does not have any relationship with the distribution the dataset typically has, we may need to consider it so the model should not be biased towards the normal cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBsLQGlR5FRF"
      },
      "outputs": [],
      "source": [
        "# isna - Missing data check\n",
        "X.isna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.isna().sum()"
      ],
      "metadata": {
        "id": "Z3UR7FgiY_z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2sMunQwRAap"
      },
      "source": [
        "**Duplicates**: Would there be any rows identical to each other?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOMY6_Pv6YhW"
      },
      "outputs": [],
      "source": [
        "X.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFiiU7xrRqrx"
      },
      "source": [
        "Would it be better to remove these conflicting instances? In this case we need to align the labels too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUQ2ip9gNE0Z"
      },
      "outputs": [],
      "source": [
        "X_dropped = X[~X.duplicated()]\n",
        "y_dropped = y[~X.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_FYnSlJ6cDO"
      },
      "outputs": [],
      "source": [
        "# Correlation check - among the features\n",
        "mat = X_dropped.corr()\n",
        "mask = np.triu(np.ones_like(mat, dtype=bool))\n",
        "fig, ax = plt.subplots(figsize = (15,10))\n",
        "ax = sns.heatmap(mat, mask=mask, annot = True, linewidths=0.5, fmt = \".2f\", square=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4saAzN1ZDk2h"
      },
      "source": [
        "We may need to apply **1) standardization** and **2) oversampling the minority** for better performance. We might be able to apply those methods one by one, but it will be better to streamline things into one pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGum53ehKyiX"
      },
      "outputs": [],
      "source": [
        "# Correlation check - features and the label\n",
        "plt.figure(figsize=(5, 12))\n",
        "heatmap = sns.heatmap(data.corr()[['fetal_health']].sort_values(by='fetal_health', ascending=True), fmt=\"0.2f\", annot=True)\n",
        "heatmap.set_title('Features correlating with the label')\n",
        "heatmap.set_ylim([0,22])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlca_fmTIlYX"
      },
      "source": [
        "### 2. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSAGFwQFxNUx"
      },
      "source": [
        "**Train test split**: After dividing the dataset into multiple parts, preprocessing like standardization or over-sampling should be applied. If not, we will end up with a cheating model that already knows part of the test information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFaDJkceNm1P"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hplPyaemyLLe"
      },
      "outputs": [],
      "source": [
        "# Create X_train, X_test, y_train, y_test using train_test_split with stratification. Set test size=0.3.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dropped, y_dropped, test_size=0.3, stratify=y_dropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrh8dTwXLKCv"
      },
      "source": [
        "**Standardization**: We can simply apply the standardization function we made in the previous lab or scikit-learn's method to standardize the dataset. This time, let's stick to scikit-learn. You can use scikit-learn's **StandardScaler** to apply standardization (= set the mean and the standard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWsclwE6LJUv"
      },
      "outputs": [],
      "source": [
        "# StandardScaler\n",
        "# X_train_scaled, X_test_scaled\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X=X_train)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)\n",
        "X_test_scaled = scaler.transform(X=X_test)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9FU--cqKwcx"
      },
      "outputs": [],
      "source": [
        "# describe - standardized mean and standard deviation\n",
        "X_train_scaled.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHwNizGYdh1B"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xot1M96rCDO"
      },
      "source": [
        "**Oversampling**: To over-sample the instances from the minority classes (2 and 3), we will use a new library called **imblearn** (which stands for Imbalanced-(scikit)-learn). This library contains various classifiers and resampling methods for imbalanced datasets. Let's use the most straightforward method it has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBZv1sa4QoH0"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9wIimtQZ318"
      },
      "outputs": [],
      "source": [
        "# Define RandomOverSampler to a variable ros\n",
        "# ratio\n",
        "ros = RandomOverSampler(random_state=12345) # random seed\n",
        "# Create X_resampled, y_resampled using the fit_resample method or fit + sample.\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUjam7lPdhV-"
      },
      "outputs": [],
      "source": [
        "# value_counts\n",
        "y_train_resampled.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV0r2G6HvNBF"
      },
      "source": [
        "Unfortunately, this simple oversampler just duplicates the instances we already have. So we can regard that it's just a weighting factor putting more weights on the minority classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I93xejvWuh42"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=[8, 4])\n",
        "ax[0].scatter(X_train_resampled.iloc[:, 0], X_train_resampled.iloc[:, 7], c=y_train_resampled, s=20, linewidth=0.5, edgecolor='black')\n",
        "ax[1].scatter(X_train_scaled.iloc[:, 0], X_train_scaled.iloc[:, 7], c=y_train, s=20, linewidth=0.5, edgecolor='black')\n",
        "ax[0].set_title(\"Resampled\")\n",
        "ax[1].set_title(\"Original\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G706ULiIrDVR"
      },
      "source": [
        "There are some more advanced techniques to resample such as **SMOTE** or **ADASYN**...\n",
        "\n",
        "- [What does SMOTE do?](https://www.researchgate.net/publication/287601878/figure/fig1/AS:316826589384744@1452548753581/The-schematic-of-NRSBoundary-SMOTE-algorithm.png)\n",
        "- [What do the others do?](https://www.kaggle.com/code/residentmario/oversampling-with-smote-and-adasyn)\n",
        "- [EasyEnsemble and BalanceCascade](https://www.kaggle.com/code/residentmario/undersampling-and-oversampling-imbalanced-data/notebook)\n",
        "- [SMOTE variants](https://imbalanced-learn.org/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html#sphx-glr-auto-examples-over-sampling-plot-comparison-over-sampling-py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMdRuCIXfXjt"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcEGJOYUd7SD"
      },
      "outputs": [],
      "source": [
        "# SMOTE, ADASYN\n",
        "# SMOTE is weak when we have a few outliers that do not contribute the classification performance.\n",
        "# X_resampled_SMOTE, y_resampled_SMOTE\n",
        "X_resampled_SMOTE, y_resampled_SMOTE = SMOTE().fit_resample(X_train_scaled, y_train)\n",
        "# X_resampled_ADASYN, y_resampled_ADASYN\n",
        "X_resampled_ADASYN, y_resampled_ADASYN = ADASYN().fit_resample(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zuj0PHSY0RdR"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=[16, 4])\n",
        "ax[0].scatter(X_train_resampled.iloc[:, 0], X_train_resampled.iloc[:, 7], c=y_train_resampled, s=20, linewidth=0.5, edgecolor='black')\n",
        "ax[1].scatter(X_resampled_SMOTE.iloc[:, 0], X_resampled_SMOTE.iloc[:, 7], c=y_resampled_SMOTE, s=20, linewidth=0.5, edgecolor='black')\n",
        "ax[2].scatter(X_resampled_ADASYN.iloc[:, 0], X_resampled_ADASYN.iloc[:, 7], c=y_resampled_ADASYN, s=20, linewidth=0.5, edgecolor='black')\n",
        "ax[3].scatter(X_train_scaled.iloc[:, 0], X_train_scaled.iloc[:, 7], c=y_train, s=20, linewidth=0.5, edgecolor='black')\n",
        "ax[0].set_title(\"Resampled_RANDOM\")\n",
        "ax[1].set_title(\"Resampled_SMOTE\")\n",
        "ax[2].set_title(\"Resampled_ADASYN\")\n",
        "ax[3].set_title(\"Original\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0guxBzplvghs"
      },
      "source": [
        "Sometimes there have been some practices to keep the minority classes at most 50% of the majority (so in our case, classes 2 and 3 won't have more than 827 instances)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eojT20azePRl"
      },
      "source": [
        "### 3. Simple ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j7_EKGveUWS"
      },
      "source": [
        "A simple ensemble model with a hard voting / soft voting can be created using scikit-learn's `VotingClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz2qIgkhJtmt"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3RDL06IJ6he"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "lr = LogisticRegression()\n",
        "svm = SVC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guLmgISCeOoP"
      },
      "outputs": [],
      "source": [
        "voting = VotingClassifier([('lr', lr), ('dt', dt), ('svm', svm)], voting='hard')\n",
        "voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUaL1mOA8ueL"
      },
      "outputs": [],
      "source": [
        "# fit the method on X_train_scaled and y_train\n",
        "voting.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvNoZGE6TrIW"
      },
      "source": [
        "Check the scores of each method and the voting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ssP0fzSgbmc"
      },
      "outputs": [],
      "source": [
        "for clf in (dt, lr, svm, voting):\n",
        "  clf.fit(X_resampled_SMOTE, y_resampled_SMOTE)\n",
        "  print(clf.__class__.__name__, clf.score(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ll2pXIRbpgA"
      },
      "outputs": [],
      "source": [
        "for clf in (dt, lr, svm, voting):\n",
        "  clf.fit(X_resampled_ADASYN, y_resampled_ADASYN)\n",
        "  print(clf.__class__.__name__, clf.score(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6EAASs6bUDi"
      },
      "outputs": [],
      "source": [
        "for clf in (dt, lr, svm, voting):\n",
        "  clf.fit(X_train_scaled, y_train)\n",
        "  print(clf.__class__.__name__, clf.score(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Jq5JZBcq8h"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUX-kAOKcs0q"
      },
      "outputs": [],
      "source": [
        "y_pred = voting.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC6nI2oJ-LBD"
      },
      "source": [
        "Those are our basic performance scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0M6lG18Ipq1"
      },
      "source": [
        "### 4. Practical ensemble methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHaxG_ukskn2"
      },
      "source": [
        "We may use some ensemble methods that were covered in the lecture. To just use those models, we can still stick to the standard scikit-learn process. Random forests and AdaBoost are supported by scikit-learn. However, you need a separate library for XGBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ddfN--3K-p3"
      },
      "source": [
        "#### Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neCoYHVjg0e_"
      },
      "source": [
        "`BaggingClassifier` supports the following modes:\n",
        " - For samples: bagging, pasting (without replacement)\n",
        " - For features: Random patches (sampling both samples and features), random subspaces (sampling only features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTVh2bikgzmd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO1IkoOKiX7c"
      },
      "outputs": [],
      "source": [
        "# max_features, bootstrap_features\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500, bootstrap = True, n_jobs = -1)\n",
        "bag_clf.fit(X_train_scaled, y_train)\n",
        "bag_clf.score(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPCE189fhHi_"
      },
      "source": [
        "**Out-of-bag evaluation**: Average the scores using the out of bag samples. To use the oob_score, you need to turn it on when you initialize the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYNi8-_ThG4c"
      },
      "outputs": [],
      "source": [
        "#oob_score = True\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500, bootstrap = True, n_jobs = -1, oob_score=True)\n",
        "bag_clf.fit(X_train_scaled, y_train)\n",
        "bag_clf.score(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpBL0MSxjP9E"
      },
      "outputs": [],
      "source": [
        "# After training, you can check the score from oob_score_.\n",
        "bag_clf.oob_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yYqOAeljYqc"
      },
      "outputs": [],
      "source": [
        "# oob_decision_function_ will show the probabilities for each oob instance\n",
        "bag_clf.oob_decision_function_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMoWNzRkvnJj"
      },
      "source": [
        "#### Random forests = Decision tree trained via bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv2FSsadDOgi"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Yx_M5RjvmAQ"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "rf.score(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48L1HnLBkfSv"
      },
      "source": [
        "Also check: [ExtraTreesClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChXrQ0xivpRG"
      },
      "source": [
        "#### AdaBoost (Adaptive Boosting) - Various classifiers / IT CANNOT BE PARALLELIZED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UzfFnqvnFcw"
      },
      "source": [
        "AdaBoost is a normal boosting algorithm, creating multiple weak learners throughout multiple phases - so each phase is dependent on the previous one. Since the weight can be applied to any classifier, you can change the base classifier as you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km3Ho2ZaGHjS"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mezTd-Pdsj54"
      },
      "outputs": [],
      "source": [
        "# AdaBoostClasifier\n",
        "# - base_estimator -> default estimator is Decision Stump\n",
        "ab = AdaBoostClassifier()\n",
        "ab.fit(X_train_scaled, y_train)\n",
        "print(ab.score(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lih3VP-h4oBJ"
      },
      "outputs": [],
      "source": [
        "# - base_estimator = LogisticRegression()\n",
        "ab = AdaBoostClassifier(estimator=LogisticRegression())\n",
        "ab.fit(X_train_scaled, y_train)\n",
        "print(ab.score(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRjR3zxvr1-"
      },
      "source": [
        "#### XGBoost (Gradient Boosting) - IT CAN BE PARALLELIZED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po5fn6A9hmhZ"
      },
      "source": [
        "XGBoost is a decision-tree-based gradient boosting classifier with more advanced tricks inside to make itself a more scalable and better performance. The key differences are as follows:\n",
        "\n",
        " - An improved data structure for better utilization such as sparse matrices\n",
        " - Better support for multicore processing.\n",
        " - L1/L2 regularization\n",
        " - Tree-node dropout\n",
        "\n",
        "\n",
        " To best exploit XGBoost, you need to perform [parameter optimization](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7W8wu0I_3n4"
      },
      "outputs": [],
      "source": [
        "# - XGBoost\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejfYlt29VN97"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the labels\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.transform(y_test)\n",
        "\n",
        "# Then train the model\n",
        "xgbm = xgb.XGBClassifier()\n",
        "xgbm.fit(X_train_scaled, y_train_encoded)\n",
        "print(xgbm.score(X_test_scaled, y_test_encoded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADVOW32-1Zwn"
      },
      "source": [
        "XGBoost also supports to handle imbalanced datasets by putting different weights based on the class distribution. For more details, [check this article](https://machinelearningmastery.com/xgboost-for-imbalanced-classification/).\n",
        "\n",
        " - scale_pos_weight with GridSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsbMOCTFkE2L"
      },
      "source": [
        "### 5. Grid search and Randomized search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R2DsUnVmyuX"
      },
      "source": [
        "#### Grid search\n",
        "\n",
        "Grid search is a method of tuning the optimal hyperparameter value by trying all possible combinations of the parameters of interest, provided by scikit-learn of python. Grid search has the disadvantage of being very expensive and time-consuming to calculate because it evaluates all combinations.\n",
        "\n",
        "#### Randomized search\n",
        "\n",
        "Randomized search finds optimal hyperparameter values by generating random numbers within a specified range. Hyperparameters are of different relative importance, and random searches are advantageous for optimization because more important parameters can be explored. In fact, there are also indicators that random searches in papers yield better results with fewer search opportunities. Random Search can stop searching at any time. This is because even if you stop in the middle, the search is not biased towards a specific range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMrz9yttXKMB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2R9G5qGzgHl"
      },
      "outputs": [],
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Our parameter distribution (or parameter grid in the case of grid search)\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hLXd_1m_m-"
      },
      "source": [
        "Compared to the grid search, the randomized search has some randomness and iterations, so it has a few more parameters such as **n_iter**, **random_state**. Also, the parameter grid is now called parameter distributions as it can also receive a distribution (such as **scipy.stats.uniform**) and sample from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTdWhjydzlLx"
      },
      "outputs": [],
      "source": [
        "# RandomizedSearchCV - create the randomized search instance with those parameters\n",
        "# - estimator: random forest\n",
        "# - param_distribution: random_grid\n",
        "# - n_iter: 100\n",
        "# - cv: 3\n",
        "\n",
        "# We also have those optional parameters\n",
        "# - random_state\n",
        "# - refit (default = True)\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOW2W22w-5t6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "rf_random.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A85NI7yiZIgf"
      },
      "outputs": [],
      "source": [
        "# best_estimator\n",
        "rf_random.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBvjoML1P0zE"
      },
      "outputs": [],
      "source": [
        "# best_score\n",
        "rf_random.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZY39EDOZAou"
      },
      "outputs": [],
      "source": [
        "# test score\n",
        "rf_random.score(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyllivmG_FKl"
      },
      "source": [
        "You can also run a grid search and see if it completes in a reasonable amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfCSjEvfS1WV"
      },
      "outputs": [],
      "source": [
        "gs_random = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 3, verbose=2, n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U9V0iZ6bcILn"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "gs_random.fit(X_train_scaled, y_train) # NEVER FINISHES!!!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dJw5E8_cKu9"
      },
      "source": [
        "Randomized search is greatly helpful when we have many options to search as it randomly choose the combination. However, it does not guarantee that it will find the optimal solution, but still it will give you similar result with the grid search. However, if you only have a limited number of parameter combinations, it is still the best to apply the grid search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6iZTuc2er8H"
      },
      "source": [
        "### 6. Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myvClh9IifsP"
      },
      "source": [
        "Most machine learning data is not ideal for building a final model. Many data transformations such as manipulating categorical variables or scaling and normalization must be performed. Scikit-Learn has built-in most commonly used functions for preprocessing functions. However, in a typical machine learning workflow, you would need to apply all these transformations more than once. Because you do it once when you train the model and again for every new data you want to predict. Of course, you can use a reusable function, but you will have to run it first and then call the model separately. The Scikit-Learn pipeline is a tool that simplifies this process and has several key advantages:\n",
        "\n",
        "- Pipelines allow you to create a single object that contains all stages of data preprocessing and classification.\n",
        "- It makes cross-validation and other types of model selection easier.\n",
        "- Increased reproducibility\n",
        "\n",
        "Using pipeline lets you manage your whole preprocessing and training process in one place and change the setting in a central place.\n",
        "- [Advanced pipeline tutorial and parameter tuning](https://towardsdatascience.com/advanced-pipelines-with-scikit-learn-4204bb71019b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMEKxnecXgsA"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBgT-VhyzqaE"
      },
      "outputs": [],
      "source": [
        "# Create a pipeline\n",
        "# - featureGenerator = PolynomialFeatures\n",
        "# - scaler = StandardScaler\n",
        "# - selector = VarianceThreshold with 0.1\n",
        "# - classifier = RandomForestClassifier\n",
        "# etc: LabelEncoder ... OneHotEncoder ... KBinsDiscretizer ... SimpleImputer\n",
        "\n",
        "pipe = Pipeline([\n",
        "  ('featureGenerator', PolynomialFeatures()),\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('selector', VarianceThreshold(0.1)),\n",
        "  ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAQ9gz4IUe_g"
      },
      "source": [
        "We can fit the pipeline in the same way as general scikit-learn classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ1GMYSOUdcB"
      },
      "outputs": [],
      "source": [
        "pipe.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzUgb_tZSfv1"
      },
      "outputs": [],
      "source": [
        "print('Training set score: ' + str(pipe.score(X_train_scaled, y_train)))\n",
        "print('Test set score: ' + str(pipe.score(X_test_scaled, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p0S8o6U0PO4"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 1</b> - Add private functions to pipelines:</span>\n",
        "\n",
        "---\n",
        "Most of the functions are supported by scikit-learn, but sometimes you may need other methods as well to change the dataset. In this case, you may have some modules that are not part of the pipeline. However, the scikit-learn pipeline also supports custom functions following some rules.\n",
        "\n",
        "The rule here is to construct a class with both fit and transform methods inside.\n",
        "\n",
        "\n",
        "\n",
        "- Create a class `SquaredFeatureTransformer` that squares the values in a numpy array and merges those squared features into the original array (i.e., the number of features is doubled). Note that we assume the dataset is in a tabular format, which means columns would be features, while rows would be instances.\n",
        "- Our dataset will have two times more features after this transformation.\n",
        "- Integrate this transformer into the pipeline, by adding the class `SquaredFeatureTransformer` with the name `squared`. The whole pipeline structure should be as follows:\n",
        "  - scaler = StandardScaler\n",
        "  - squared = SquaredFeatureTransformer\n",
        "  - selector = VarianceThreshold with 0.1 variance threshold\n",
        "  - classifier = RandomForestClassifier\n",
        "- Eventually, the pipeline should have four elements: `scaler`, `squared`, `selector`, and `classifier`. Define this pipeline to the variable pipe.\n",
        "- Understand how to create a custom transformer function.\n",
        "\n",
        "Please note that in the grading system on nextilearn, all necessary libraries are already imported. Do not import any libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIYqnzuk0PO4"
      },
      "outputs": [],
      "source": [
        "class SquaredFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "  #This class will transform the dataset by adding squared features\n",
        "  #You need to change the transform function to square each feature's values and add them to the matrix.\n",
        "\n",
        "  def __init__(self):\n",
        "    return None\n",
        "\n",
        "  def fit(self, X, y = None):\n",
        "    return None\n",
        "\n",
        "  def transform(self, X, y = None):\n",
        "    return None\n",
        "\n",
        "pipe = None # CHANGE IT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRKXzKua0PO4"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 2</b> - Integrate grid search into pipelines:</span>\n",
        "\n",
        "---\n",
        "So far, we have learned randomized search and grid search for a parameter search of a specific model and the scikit-learn pipeline to streamline the complete machine learning task from preprocessing to model training. Then the remaining question is how we can also integrate the model selection process - like the parameter search we performed using the grid search and the randomized search - into the pipeline.\n",
        "\n",
        "By adding those parameter tests, you can also change the modules that should be in the same name: for example, you can have `[StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()]` in a name 'scaler' of the pipeline. Moreover, you can perform a grid test if they have the common parameters - they usually have.\n",
        "\n",
        "Define a new variable parameters and customize the options by creating a dictionary. You can change the pipeline values by setting the same key as you did for the pipeline. For example, if you would like to test two scalers, you can put 'scaler': [scaler1, scaler2].\n",
        "\n",
        "Create the following key-values in the parameters dictionary.\n",
        "\n",
        " - scaler: `[StandardScaler(), MinMaxScaler()]`.\n",
        " - classifier: `[AdaBoostClassifier(), RandomForestClassifier()]`.\n",
        "\n",
        "You can also search for many parameter options by using underscores. Please check this guideline. If you want to test the threshold parameter of the selector (here, we use `VarianceThreshold` as a selector).\n",
        "\n",
        "Your parameter grid should also have a threshold for `VarianceThreshold` with the values `[0, 0.001, 0.01]`.\n",
        "\n",
        "Define a grid search with cross validation into the variable grid_search. You can put the predefined pipeline instance pipe as a classifier and should use your parameter grid. The search should run 5-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gih52znl0PO4"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "parameters = None # CHANGE IT\n",
        "\n",
        "# Run grid search\n",
        "grid_search = None # CHANGE IT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yMNo-MI0PO4"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 3</b> - Nested k-fold cross validation:</span>\n",
        "\n",
        "---\n",
        "\n",
        "In this exercise, you will implement nested k-fold cross-validation using Scikit-Learn to evaluate and compare different machine learning models while tuning their hyperparameters. The goal is to perform model selection in a robust and unbiased manner, ensuring that hyperparameter tuning and model evaluation are conducted on separate data splits. You will work with the breast_cancer dataset from sklearn.datasets, where the objective is to classify whether a tumor is malignant or benign. Please check this guideline to see how to open the dataset.\n",
        "\n",
        "You will define a pipeline that includes a scaler (`StandardScaler`), a feature selector (`VarianceThreshold`), and a classifier. Two classifiers will be tested: `RandomForestClassifier` and `AdaBoostClassifier`. Each classifier will have a specific set of hyperparameters to tune:\n",
        "\n",
        "- **RandomForestClassifier parameters**:\n",
        "  - `n_estimators: [50, 100]`\n",
        "  - `max_depth: [None, 10]`\n",
        "- **AdaBoostClassifier parameters**:\n",
        "  - `n_estimators: [50, 100]`\n",
        "  - `learning_rate: [0.01, 0.1]`\n",
        "\n",
        "You may create a dictionary called `param_grids` having two keys `'RandomForest', 'AdaBoost'` where each has a parameter grid for each classifier as a value. Then you will apply nested cross-validation with:\n",
        "\n",
        "Outer loop (2-fold stratified cross-validation): Splits the dataset into 2 folds, where 1 fold is used as the test set and the remaining 4 folds are used for training. For this instance, set the random state to 42 and shuffle the dataset.\n",
        "Inner loop (2-fold stratified cross-validation using `GridSearchCV`): Finds the best hyperparameters for each classifier on the training set of the outer loop. For this instance, set the random state to 42 and shuffle the dataset.\n",
        "\n",
        "For each outer loop iteration, fit the best model (determined by `GridSearchCV`) on the training data and evaluate it on the outer test set. At the end, compute the mean accuracy across all outer folds to compare the models. The classifier with the highest mean accuracy across the outer folds is considered the best model for this dataset. Save the final accuracy value into the variable final_accuracy in the format of dictionary with two keys: `'RandomForest', 'AdaBoost'`. For validation, make sure to set the random state of `RandomForestClassifier` and `AdaBoostClassifier` to 42.\n",
        "\n",
        "Note that while we provide you with skeleton code, you are free to implement in your own preferred way. We will only validate the `final_score` dictionary if the average performance is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77vqDTVQ0PO4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}