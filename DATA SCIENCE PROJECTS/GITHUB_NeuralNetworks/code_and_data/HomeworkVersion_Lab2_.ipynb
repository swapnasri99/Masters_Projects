{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb7Nui77r_v"
      },
      "source": [
        "# Lab 2. PyTorch models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aalcduo8_B-M"
      },
      "source": [
        "---\n",
        "\n",
        "How to Use This Notebook\n",
        "---\n",
        "\n",
        "**Recommended Setup**\n",
        "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
        "- In Colab, **enable GPU support** by going to:  \n",
        "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
        "\n",
        "\n",
        "**Homework Tasks**\n",
        "\n",
        " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > ```Your code ....```\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > *End of Task X.* [*Instructions for passing*]\n",
        "\n",
        " - For each task:\n",
        "   - **Complete the code** where indicated.\n",
        "   - **Upload the required results** from each task to **Homework 2 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        " - Once you've finished all the tasks:\n",
        "   Submit your **entire completed notebook (including your code!)** to **Homework 2 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        "**Important:**  \n",
        "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIH0AWH2_jxD"
      },
      "source": [
        "This lab will teach how to use PyTorch by making a simple neural network model. Regradless of model's complexity, creating any model can be completed in a similar way. We will use the **Fashion MNIST** dataset, one of the variants of the MNIST dataset. It has the same property as a normal MNIST, with the same size (28*28) and the same number of classes (10), but the images represent fashion items rather than handwritten digits, which means it might have more complexity than normal MNIST.\n",
        "\n",
        "Because of its complexity in each class, the problem is significantly more challenging than normal MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST. Below is an example of Fashion MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gQUsFpCD0aP"
      },
      "source": [
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBXx3rp8D2Nm"
      },
      "source": [
        "\n",
        "In today's lab, we will first try to create a simple fully connected network model and check its basic performance on Fashion MNIST.\n",
        "\n",
        "Based on your local machine's performance, the task might take a long time, so it is recommended to use the [Google Colab](https://colab.research.google.com/) since it can handle the lab contents with no processing bottleneck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ChFhB0bauM"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiDj5c8beHt"
      },
      "source": [
        "- Import PyTorch and load a sample dataset\n",
        "- Sequential fully connected network\n",
        "- Other useful functions (Saving/Loading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDXwomm0bxug"
      },
      "source": [
        "### Section 1: Import PyTorch and load a sample dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9hfGXIA6Ek"
      },
      "source": [
        "You should be able to install PyTorch by using `pip`. You do not need to specify a GPU version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jzUBH9xhn0JL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y7mgvEN8mtN6"
      },
      "outputs": [],
      "source": [
        "import torch as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I8zL6JdKIasB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1Ek6pMT_pdg_",
        "outputId": "1770fb96-2347-4185-e034-4daa95cee1f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# version?\n",
        "pt.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhFeXn8MgFT2"
      },
      "source": [
        "We will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data available in github, which has 70,000 article images. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Since it is on github we can simple get it by using `git clone [repo] [folder]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McfKi-cJn0JP",
        "outputId": "a2e37160-91e6-400a-c247-e07a48ed8051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 762, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 762 (delta 0), reused 2 (delta 0), pack-reused 758 (from 1)\u001b[K\n",
            "Receiving objects: 100% (762/762), 105.85 MiB | 48.80 MiB/s, done.\n",
            "Resolving deltas: 100% (444/444), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zalandoresearch/fashion-mnist data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6efgvJL-WwWu"
      },
      "source": [
        "#### Dataset handling: Traditional way with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lga5zwx6BJti"
      },
      "source": [
        "Datasets can be found in diverse locations -- e.g. on [github](https://github.com/), [zenodo](https://zenodo.org/), [huggingface](https://huggingface.co/docs/hub/en/datasets), [kaggle](https://www.kaggle.com/datasets) or **your companies server**. Some Python modules like `torch` and `tensorflow` also have their own easy-to-use versions of standard datasets specialised to the specific library. For a fast, but less general alternative to this tutorial, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). **The linked tutorial is for interrested students and not part of this assignment!**\n",
        "\n",
        "If the dataset is hosted on github or similar, the first step is to check the description: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist#get-the-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SSWdpC1tjnL"
      },
      "source": [
        "Lets check out the `mnist_reader` they mention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYgIPJnr4Cz",
        "outputId": "47583128-28e3-4ee9-87cf-e26212322888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def load_mnist(path, kind='train'):\n",
            "    import os\n",
            "    import gzip\n",
            "    import numpy as np\n",
            "\n",
            "    \"\"\"Load MNIST data from `path`\"\"\"\n",
            "    labels_path = os.path.join(path,\n",
            "                               '%s-labels-idx1-ubyte.gz'\n",
            "                               % kind)\n",
            "    images_path = os.path.join(path,\n",
            "                               '%s-images-idx3-ubyte.gz'\n",
            "                               % kind)\n",
            "\n",
            "    with gzip.open(labels_path, 'rb') as lbpath:\n",
            "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
            "                               offset=8)\n",
            "\n",
            "    with gzip.open(images_path, 'rb') as imgpath:\n",
            "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
            "                               offset=16).reshape(len(labels), 784)\n",
            "\n",
            "    return images, labels\n"
          ]
        }
      ],
      "source": [
        "!cat data/utils/mnist_reader.py # linux / mac\n",
        "#!type data\\utils\\mnist_reader.py # windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-Nz93XtsRy"
      },
      "source": [
        "What values does the parameter `kind` take?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXvbQYytQfW",
        "outputId": "6f2dc02d-9801-4551-911b-df51f0f99558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train-labels-idx1-ubyte.gz',\n",
              " 't10k-labels-idx1-ubyte.gz',\n",
              " 't10k-images-idx3-ubyte.gz',\n",
              " 'train-images-idx3-ubyte.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('data/data/fashion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsK-umdt4pc"
      },
      "source": [
        "Let's load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_i0BcD_qwx0"
      },
      "outputs": [],
      "source": [
        "# import mnist_reader:\n",
        "import data.utils.mnist_reader as mnist_reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g2DoMiOnplgm"
      },
      "outputs": [],
      "source": [
        "# load data:\n",
        "X_train_full, y_train_full = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "X_test, y_test = mnist_reader.load_mnist('data/data/fashion', kind='t10k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KfXaFeBQLY"
      },
      "source": [
        "This dataset is loaded as a NumPy array which we learned before in Lab 1. You can use all the methods you learned to check the properties of the dataset, like **shape** or **describe**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQGzWUZABSdD",
        "outputId": "266e929d-8012-4bd3-9c30-21be32a71d47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# type?\n",
        "type(X_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA4f__FUppwQ",
        "outputId": "a3d0a934-f0c8-4bfb-fd7c-d7ec7282a13f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# shape?\n",
        "X_train_full.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRWMKbUZnJJ",
        "outputId": "42f359d4-6c27-45cf-9102-ff0582bea29a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "np.unique(y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSk4-jABU95"
      },
      "source": [
        "As the dataset is composed of grayscale pixels, the datatype of it is unsigned integer. The dataset also has a pixed range [0, 255] so it does not need to take higher bit than 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdNJONOHptj6",
        "outputId": "7e877d41-b223-4e92-9722-3fa6c9a05b19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# dtype?\n",
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZE6WfngbYs"
      },
      "source": [
        "Besides that, PyTorch models are also usually evaluated by one more separate set called validation set as training is an iterative and time-consuming process and we do not know when we need to stop clearly. So we would like to estimate the right time to interrupt the training process by checking its performance for each iteration.\n",
        "\n",
        "To create a validation set, there can be many options, we can explicitly split the dataset using index, or we can just use a training set but with the option stating we want to validate, when we actually fit the model. However, this time we will use scikit-learn's `train_test_split` method to create a validation set as it can provide a nice stratification option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUEmqGNGoZ_W"
      },
      "source": [
        "We need a simiple normalization - as we all know the graysclae ranges from 0 to 255..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lb6n6PzLgjRj"
      },
      "outputs": [],
      "source": [
        "# Introduced in the coursebook\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "azOEHFspR7u5"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtvJAWxvhEP"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 1</b> - Stratified Split:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Replace the above simple training/validation split with a **stratified** one (50% train, 50% validation):\n",
        "  - Use `X_train_full` and `y_train_full`\n",
        "  - Enable `shuffle` and `stratification`\n",
        "\n",
        "Use [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Print and check their shapes afterward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yQuXXouFLDRN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# normalize:\n",
        "X_train_full = X_train_full / 255.\n",
        "\n",
        "# split data:\n",
        "X_train, X_valid, y_train, y_valid =train_test_split(X_train_full,y_train_full,train_size=0.5,shuffle=True,stratify = y_train_full) #continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r4gVzDXcR7u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084eb786-0791-488d-d162-6accb66d3541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 784)\n",
            "(30000, 784)\n",
            "(30000,)\n",
            "(30000,)\n"
          ]
        }
      ],
      "source": [
        "# shape?\n",
        "#continue\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_f0SkwQR7u7"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 1. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTSsrnEF2XC"
      },
      "source": [
        "Here we prepared the class names of the fashion MNIST dataset for your convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vRc7tKoIsFx4"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eBOMMsxAxrfj",
        "outputId": "fe7db6c1-8f63-4315-adc4-4aaad99bd311"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T-shirt/top'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Use the numeric label to get the class name, e.g:\n",
        "class_names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch49P29iEDxC"
      },
      "source": [
        "We can also try to see each data instance by using **plt.imshow**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FSwEtbA6KmFg",
        "outputId": "5609bb51-22ac-4a6f-feb0-703d2abe3d6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = np.random.randint(0, X_train.shape[0])\n",
        "plt.imshow(X_train[i].reshape((28, 28)), cmap='gray') # cmap to make it recognize grayscale\n",
        "plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPR-OZKyStX"
      },
      "source": [
        "#### Optimizing memory consuption using pipelines:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w2ohRDo2eW"
      },
      "source": [
        "Imagine taking the above approach with very large datasets (e.g. used for training modern LLMs). Loading all the data before training would exceed RAM and VRAM of almost any computer.\n",
        "\n",
        "Therefore, we are going to use the [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) API:\n",
        "\n",
        "---\n",
        "***An abstract class representing a Dataset.***\n",
        "\n",
        "*All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite* `__getitem__()`*, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite* `__len__()`*, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader. Subclasses could also optionally implement* `__getitems__()`*, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xcvyxGDerVFS"
      },
      "outputs": [],
      "source": [
        "from numpy.typing import NDArray\n",
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, X:NDArray[np.int8], y:NDArray[np.int8]) -> None:\n",
        "    # normalize:\n",
        "    self.X = X.astype(np.float32) / 255.0\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "\n",
        "    # load data:\n",
        "    train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "    t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "    data   = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "    labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "    # split data:\n",
        "    n = len(labels)\n",
        "    n_train = int(n * fraction_train)\n",
        "    n_validation = int(n * fraction_validation)\n",
        "\n",
        "    data_train = FashionMNIST(\n",
        "        data[:n_train],\n",
        "        labels[:n_train]\n",
        "    )\n",
        "    data_valid = FashionMNIST(\n",
        "        data[n_train:n_train+n_validation],\n",
        "        labels[n_train:n_train+n_validation]\n",
        "    )\n",
        "    data_test = FashionMNIST(\n",
        "        data[n_train+n_validation:],\n",
        "        labels[n_train+n_validation:]\n",
        "    )\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0v0JjVOk57s"
      },
      "source": [
        "It works like a list of tuples `(X, y)` in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SCOTVO81lZyD"
      },
      "outputs": [],
      "source": [
        "data, _, _ = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjOC4aIlpfp",
        "outputId": "a41b2e63-a38b-41bf-9090-23741a91574a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# call to __len__:\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFLbrYUlrdL",
        "outputId": "2b3cfe11-156b-4509-a01e-067b455f5906"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
              "        0.34509805, 0.7372549 , 0.6745098 , 0.5176471 , 0.49019608,\n",
              "        0.5529412 , 0.78039217, 0.56078434, 0.03529412, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.07843138,\n",
              "        0.5137255 , 0.78039217, 0.80784315, 0.76862746, 0.7921569 ,\n",
              "        0.9490196 , 1.        , 1.        , 0.98039216, 0.87058824,\n",
              "        0.77254903, 0.80784315, 0.7372549 , 0.49411765, 0.06666667,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.13725491, 0.8392157 , 0.7490196 , 0.7176471 ,\n",
              "        0.69803923, 0.6862745 , 0.65882355, 0.5882353 , 0.63529414,\n",
              "        0.62352943, 0.59607846, 0.61960787, 0.7019608 , 0.7176471 ,\n",
              "        0.7411765 , 0.7647059 , 0.7254902 , 0.32156864, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
              "        0.74509805, 0.6745098 , 0.69411767, 0.6901961 , 0.67058825,\n",
              "        0.6627451 , 0.63529414, 0.60784316, 0.5803922 , 0.6039216 ,\n",
              "        0.6627451 , 0.68235296, 0.6862745 , 0.6862745 , 0.69411767,\n",
              "        0.7176471 , 0.7372549 , 0.04705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09803922, 0.7607843 , 0.7058824 , 0.69803923,\n",
              "        0.68235296, 0.72156864, 0.73333335, 0.7411765 , 0.73333335,\n",
              "        0.72156864, 0.70980394, 0.7411765 , 0.78431374, 0.77254903,\n",
              "        0.75686276, 0.74509805, 0.69803923, 0.6862745 , 0.7607843 ,\n",
              "        0.3529412 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.16470589,\n",
              "        0.85490197, 0.7490196 , 0.77254903, 0.8156863 , 0.8       ,\n",
              "        0.827451  , 0.81960785, 0.8235294 , 0.83137256, 0.827451  ,\n",
              "        0.8392157 , 0.84313726, 0.8352941 , 0.8392157 , 0.827451  ,\n",
              "        0.827451  , 0.7490196 , 0.78431374, 0.61960787, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34509805, 0.8666667 , 0.84313726,\n",
              "        0.8509804 , 0.85882354, 0.827451  , 0.7254902 , 0.5882353 ,\n",
              "        0.4627451 , 0.41960785, 0.3882353 , 0.34509805, 0.3254902 ,\n",
              "        0.3529412 , 0.5294118 , 0.83137256, 0.79607844, 0.8117647 ,\n",
              "        0.85882354, 0.6627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10588235, 0.4627451 , 0.63529414, 0.15686275,\n",
              "        0.        , 0.        , 0.        , 0.03921569, 0.07450981,\n",
              "        0.10980392, 0.15294118, 0.18431373, 0.14117648, 0.        ,\n",
              "        0.        , 0.79607844, 0.9019608 , 0.8627451 , 0.79607844,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.5411765 , 0.53333336,\n",
              "        0.2784314 , 0.27058825, 0.21176471, 0.84705883, 0.8509804 ,\n",
              "        0.79607844, 0.72156864, 0.65882355, 0.6392157 , 0.63529414,\n",
              "        0.6392157 , 0.69803923, 0.8666667 , 0.7294118 , 0.14901961,\n",
              "        0.10196079, 0.02745098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2627451 , 0.5254902 , 0.6039216 , 0.8784314 ,\n",
              "        0.5058824 , 0.25882354, 0.31764707, 0.45882353, 0.5058824 ,\n",
              "        0.5019608 , 0.5176471 , 0.5372549 , 0.5137255 , 0.5058824 ,\n",
              "        0.3372549 , 0.28627452, 0.6156863 , 0.5921569 , 0.5254902 ,\n",
              "        0.84705883, 0.07058824, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.79607844,\n",
              "        0.7764706 , 0.6745098 , 0.7176471 , 0.80784315, 1.        ,\n",
              "        1.        , 0.98039216, 0.9529412 , 0.9411765 , 0.9372549 ,\n",
              "        0.92156863, 0.93333334, 0.95686275, 1.        , 0.93333334,\n",
              "        0.72156864, 0.627451  , 0.3372549 , 0.38431373, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.47843137, 0.7372549 , 0.8784314 ,\n",
              "        0.5921569 , 0.4117647 , 0.49803922, 0.38039216, 0.39215687,\n",
              "        0.4117647 , 0.44705883, 0.45882353, 0.45882353, 0.44313726,\n",
              "        0.40392157, 0.38431373, 0.43529412, 0.5568628 , 0.99607843,\n",
              "        0.7490196 , 1.        , 0.19215687, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.6392157 , 0.7019608 , 0.78431374, 0.37254903, 0.6039216 ,\n",
              "        0.7764706 , 0.77254903, 0.78431374, 0.78431374, 0.7764706 ,\n",
              "        0.77254903, 0.7764706 , 0.78039217, 0.7921569 , 0.78431374,\n",
              "        0.6901961 , 0.3372549 , 0.80784315, 0.6156863 , 0.63529414,\n",
              "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.77254903, 0.7882353 ,\n",
              "        0.8980392 , 0.2784314 , 0.5647059 , 0.7607843 , 0.70980394,\n",
              "        0.7176471 , 0.7019608 , 0.7137255 , 0.7058824 , 0.7019608 ,\n",
              "        0.7058824 , 0.74509805, 0.7254902 , 0.77254903, 0.29803923,\n",
              "        0.85882354, 0.7254902 , 0.7882353 , 0.13333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.78039217, 0.75686276, 0.8862745 , 0.22745098,\n",
              "        0.6039216 , 0.7529412 , 0.72156864, 0.73333335, 0.72156864,\n",
              "        0.7294118 , 0.72156864, 0.7254902 , 0.7176471 , 0.7529412 ,\n",
              "        0.7490196 , 0.78431374, 0.21960784, 0.85882354, 0.79607844,\n",
              "        0.8117647 , 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.7882353 ,\n",
              "        0.7607843 , 0.8784314 , 0.16078432, 0.6392157 , 0.74509805,\n",
              "        0.7294118 , 0.7294118 , 0.72156864, 0.7254902 , 0.7176471 ,\n",
              "        0.7254902 , 0.69803923, 0.74509805, 0.7607843 , 0.7921569 ,\n",
              "        0.12941177, 0.827451  , 0.78431374, 0.80784315, 0.28627452,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.7882353 , 0.77254903, 0.87058824,\n",
              "        0.06666667, 0.6745098 , 0.74509805, 0.7294118 , 0.73333335,\n",
              "        0.7137255 , 0.7294118 , 0.7254902 , 0.73333335, 0.7058824 ,\n",
              "        0.73333335, 0.75686276, 0.7921569 , 0.10196079, 0.83137256,\n",
              "        0.7921569 , 0.79607844, 0.29803923, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.78431374, 0.77254903, 0.8745098 , 0.        , 0.69411767,\n",
              "        0.7411765 , 0.72156864, 0.7254902 , 0.69803923, 0.72156864,\n",
              "        0.7176471 , 0.72156864, 0.7058824 , 0.7176471 , 0.7411765 ,\n",
              "        0.79607844, 0.13725491, 0.76862746, 0.79607844, 0.79607844,\n",
              "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.78431374, 0.77254903,\n",
              "        0.8745098 , 0.        , 0.7254902 , 0.73333335, 0.7254902 ,\n",
              "        0.73333335, 0.7058824 , 0.72156864, 0.7137255 , 0.7176471 ,\n",
              "        0.69803923, 0.7137255 , 0.7176471 , 0.8039216 , 0.17254902,\n",
              "        0.62352943, 0.8117647 , 0.7882353 , 0.33333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.73333335, 0.7764706 , 0.88235295, 0.        ,\n",
              "        0.7607843 , 0.7372549 , 0.72156864, 0.7254902 , 0.7058824 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.70980394, 0.70980394,\n",
              "        0.69411767, 0.80784315, 0.18039216, 0.5058824 , 0.827451  ,\n",
              "        0.78431374, 0.34509805, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.7294118 ,\n",
              "        0.78431374, 0.827451  , 0.        , 0.78039217, 0.7411765 ,\n",
              "        0.72156864, 0.72156864, 0.7254902 , 0.7137255 , 0.7176471 ,\n",
              "        0.72156864, 0.7254902 , 0.7137255 , 0.6862745 , 0.8039216 ,\n",
              "        0.19607843, 0.38039216, 0.84705883, 0.77254903, 0.3647059 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.7254902 , 0.8       , 0.72156864,\n",
              "        0.        , 0.7921569 , 0.7372549 , 0.7137255 , 0.7137255 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.7137255 , 0.7058824 ,\n",
              "        0.7137255 , 0.68235296, 0.7921569 , 0.24705882, 0.23137255,\n",
              "        0.8627451 , 0.76862746, 0.36862746, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
              "        0.72156864, 0.80784315, 0.6156863 , 0.        , 0.8       ,\n",
              "        0.73333335, 0.73333335, 0.7411765 , 0.7529412 , 0.74509805,\n",
              "        0.74509805, 0.7490196 , 0.74509805, 0.73333335, 0.7176471 ,\n",
              "        0.7921569 , 0.30588236, 0.13725491, 0.87058824, 0.77254903,\n",
              "        0.37254903, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01960784, 0.7176471 , 0.8156863 ,\n",
              "        0.49803922, 0.        , 0.77254903, 0.6509804 , 0.6       ,\n",
              "        0.58431375, 0.58431375, 0.57254905, 0.5803922 , 0.58431375,\n",
              "        0.5882353 , 0.5921569 , 0.61960787, 0.7490196 , 0.3529412 ,\n",
              "        0.03137255, 0.8745098 , 0.7647059 , 0.3882353 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.72156864, 0.8156863 , 0.44705883, 0.        ,\n",
              "        0.8       , 0.6784314 , 0.6313726 , 0.7058824 , 0.6901961 ,\n",
              "        0.6745098 , 0.6784314 , 0.6784314 , 0.68235296, 0.6901961 ,\n",
              "        0.63529414, 0.7921569 , 0.4509804 , 0.        , 0.8980392 ,\n",
              "        0.78039217, 0.4117647 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03529412, 0.69803923,\n",
              "        0.8       , 0.4509804 , 0.        , 0.4745098 , 0.5294118 ,\n",
              "        0.44705883, 0.45882353, 0.44705883, 0.44705883, 0.45882353,\n",
              "        0.4627451 , 0.46666667, 0.45882353, 0.44313726, 0.5764706 ,\n",
              "        0.24705882, 0.        , 0.88235295, 0.76862746, 0.41960785,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.7058824 , 0.80784315, 0.5137255 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.8784314 , 0.77254903, 0.48235294, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5529412 , 0.5921569 , 0.29803923, 0.        , 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.52156866, 0.654902  ,\n",
              "        0.28627452, 0.        , 0.        , 0.        ], dtype=float32),\n",
              " np.uint8(2))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# call to __getitem__:\n",
        "data[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1u-U7X-fXCB"
      },
      "source": [
        "But the above implementation still loads everything at the time of instantiation of the `FashionMNIST` class. So let's transform the data into a format that you see more often with big datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EADlbbqB01Kw"
      },
      "outputs": [],
      "source": [
        "# unzip data:\n",
        "target_dir = 'data/data/fashion/unzipped'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "data = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "for i, x in enumerate(data):\n",
        "  file = os.path.join(target_dir, f'img_{i:d}.npy')\n",
        "  with open(file, 'wb') as f:\n",
        "    np.save(f, x.reshape((28, 28)))\n",
        "\n",
        "with open(os.path.join(target_dir, 'labels.npy'), 'wb') as f:\n",
        "  np.save(f, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0YptsZ-QaG",
        "outputId": "3238efb0-05e6-43ea-e4ca-53e700eafdec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_8870.npy',\n",
              " 'img_9736.npy',\n",
              " 'img_31374.npy',\n",
              " 'img_55029.npy',\n",
              " 'img_37107.npy',\n",
              " 'img_11232.npy',\n",
              " 'img_42075.npy',\n",
              " 'img_66632.npy',\n",
              " 'img_45518.npy',\n",
              " 'img_68735.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "os.listdir(target_dir)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrICJqXvjc1Y"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 2</b> - Dataset:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following class.\n",
        "- It should load every single sample dynamically from disk when it is requested and this way keep memory consumption to a minimum.\n",
        "- Use your code from Task 1 to create stratified splits using the `stratify` and `shuffle` arguments of `create_split`.\n",
        "- Use the variable `target_dir` as the path to the unzipped data.\n",
        "- **Make sure it produces the the right type of outputs (see type hintig and class above)!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VmiKviaXkHYb"
      },
      "outputs": [],
      "source": [
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, indices:NDArray[np.int32], labels:NDArray[np.int8]) -> None:\n",
        "    self.indices = indices\n",
        "    self.labels  = labels\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.indices)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    # complete\n",
        "    index = self.indices[idx]\n",
        "    label = self.labels[idx]\n",
        "    file_path = os.path.join(target_dir,f'img_{index}.npy')\n",
        "    image = np.load(file_path).astype(np.float32).reshape(-1)/255.0\n",
        "    return image,label\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float, stratify:bool=True, shuffle:bool=True) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "    # complete\n",
        "    labels_file = os.path.join(target_dir,'labels.npy')\n",
        "    labels = np.load(labels_file)\n",
        "    indices = np.arange(len(labels))\n",
        "\n",
        "    train_indices,temp_indices,y_train,y_temp = train_test_split(indices,labels,train_size=fraction_train,shuffle=shuffle,stratify=labels if stratify else None)\n",
        "\n",
        "    fraction_remaining = fraction_validation + fraction_test\n",
        "    fraction_val_new = fraction_validation/fraction_remaining\n",
        "\n",
        "    valid_indices,test_indices,y_valid,y_test = train_test_split(temp_indices,y_temp,train_size=fraction_val_new,shuffle=shuffle,stratify=y_temp if stratify else None)\n",
        "\n",
        "    data_train = FashionMNIST(train_indices,y_train)\n",
        "    data_valid = FashionMNIST(valid_indices,y_valid)\n",
        "    data_test = FashionMNIST(test_indices,y_test)\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxU6CLfR7vD"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 2. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRzLUn4kGGVU"
      },
      "source": [
        "Our objective is to create a model with the high accuracy on this dataset. Let's start to create our first model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ox0oodObDPH"
      },
      "source": [
        "**Shuffling and batching**: Using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), you can easily shuffle and batch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QdYJGAsARQxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BZmqQ9W2pp5b"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid, data_test = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W2dJNcKrESEU"
      },
      "outputs": [],
      "source": [
        "loader_train = DataLoader(data_train,             # dataset from which to load the data.\n",
        "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1).\n",
        "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False).\n",
        "                          sampler=None,           # defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented.\n",
        "                                                  # If specified, shuffle must not be specified.\n",
        "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
        "                          drop_last=False)        # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
        "                                                  # If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Tj964nU9EVbq"
      },
      "outputs": [],
      "source": [
        "# validation set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_valid = DataLoader(data_valid,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nu56t0MPO1PF"
      },
      "outputs": [],
      "source": [
        "# test set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_test  = DataLoader(data_test,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewz-SbwJxZ1t"
      },
      "source": [
        "### Section 2: Sequential fully connected network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fh7PjMWqOnS"
      },
      "source": [
        "#### Instantiating the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuxZ7HZgpwm"
      },
      "source": [
        "The standard way to create a PyTorch model is to override the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. To create a model you need to override the following methods:\n",
        "- `__init__(self, ...) -> None`: Initializes the module and instantiates all the layers and functions.\n",
        "- `forward(self, x) -> y`: implements the forward pass through the network.\n",
        "\n",
        "When you create a layer (e.g. [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)), you should specify **in_features** and **out_features**. Don't forget to apply an **activation function** in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dpDMjCbExvzN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(in_features=784, out_features=100, bias=True)\n",
        "        self.layer2 = nn.Linear(in_features=100, out_features=len(class_names), bias=True)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        x = F.relu(self.layer1(x))\n",
        "        return F.softmax(self.layer2(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvjomL9CJcrr"
      },
      "source": [
        "We can visualize the model using **keras.utils.plot_model**. It helps to figue out (or validate) the structure of complete models having multiple paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iLn73SNJenS",
        "outputId": "1558ba41-a75f-401c-9749-310c49d748c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CustomNetwork()\n",
        "summary(model, input_size=(784,), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_iVtGfSEe7b"
      },
      "source": [
        "Summarization of model parameters is only possible when the model has an input information as it needs to calculate the fully connected parameters from the input layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEOcLYKLEpgw"
      },
      "source": [
        "A model instance has various attributes to get layers, weights - which are just for your reference to check the real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5iYpVqcwYL9",
        "outputId": "12402de7-5cb6-4a60-c73d-2aeb13ba083f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=100, bias=True),\n",
              " Linear(in_features=100, out_features=10, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# You can get a generator object of properties of type `torch.nn.Module` using `children()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwCNTJ4nGyW",
        "outputId": "7e52d1bf-8550-4714-bea3-fb1ae6949bc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "list(model.named_children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJcb7xZtpEAZ",
        "outputId": "bb55cc3b-1391-4d8d-d6c2-ce2b404e27a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=100, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.get_submodule('layer1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnS08_Lom1s",
        "outputId": "1ea945a0-7b4a-4133-e23d-bae938c8775c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  CustomNetwork(\n",
              "    (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
              "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )),\n",
              " ('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# All modules in the model (including itself):\n",
        "list(model.named_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAa1OQuPnlNF",
        "outputId": "f6bee6cc-236c-4da6-a9bb-811cac4ca0b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0119, -0.0353, -0.0085,  ..., -0.0141, -0.0006, -0.0157],\n",
              "         [-0.0288, -0.0321, -0.0197,  ..., -0.0129, -0.0137,  0.0344],\n",
              "         [ 0.0055,  0.0250, -0.0125,  ..., -0.0257, -0.0194,  0.0250],\n",
              "         ...,\n",
              "         [ 0.0042,  0.0273, -0.0345,  ..., -0.0346,  0.0349,  0.0238],\n",
              "         [ 0.0117,  0.0291, -0.0344,  ...,  0.0272,  0.0224, -0.0257],\n",
              "         [ 0.0293,  0.0287, -0.0169,  ...,  0.0044,  0.0262, -0.0014]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0110, -0.0319,  0.0018,  0.0006, -0.0011, -0.0099,  0.0251,  0.0085,\n",
              "          0.0307,  0.0320, -0.0138, -0.0069,  0.0318, -0.0118,  0.0154,  0.0094,\n",
              "          0.0327, -0.0164,  0.0105,  0.0156,  0.0109, -0.0280,  0.0262, -0.0343,\n",
              "         -0.0023, -0.0033,  0.0117,  0.0126,  0.0167,  0.0020,  0.0275,  0.0275,\n",
              "         -0.0184, -0.0019, -0.0192,  0.0074,  0.0297, -0.0012, -0.0223, -0.0207,\n",
              "         -0.0260,  0.0158, -0.0093,  0.0330, -0.0344, -0.0273, -0.0199,  0.0263,\n",
              "         -0.0068, -0.0263,  0.0144, -0.0320,  0.0014, -0.0015, -0.0219,  0.0116,\n",
              "          0.0075, -0.0133, -0.0144,  0.0039,  0.0171, -0.0098, -0.0323, -0.0044,\n",
              "         -0.0256, -0.0266, -0.0106,  0.0218,  0.0197,  0.0216,  0.0266,  0.0060,\n",
              "         -0.0145, -0.0356, -0.0084, -0.0072,  0.0258,  0.0132,  0.0240, -0.0209,\n",
              "          0.0051,  0.0188,  0.0027, -0.0029,  0.0205,  0.0059, -0.0086,  0.0265,\n",
              "         -0.0311, -0.0038,  0.0100, -0.0333,  0.0004, -0.0241, -0.0036, -0.0125,\n",
              "          0.0153, -0.0162, -0.0153,  0.0069], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# You can get a generator object of parameters (weights) for each submodule using `parameters()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUW334iaoA7z",
        "outputId": "92737294-9f3f-43d3-e868-5826927fc9a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.0119, -0.0353, -0.0085,  ..., -0.0141, -0.0006, -0.0157],\n",
              "          [-0.0288, -0.0321, -0.0197,  ..., -0.0129, -0.0137,  0.0344],\n",
              "          [ 0.0055,  0.0250, -0.0125,  ..., -0.0257, -0.0194,  0.0250],\n",
              "          ...,\n",
              "          [ 0.0042,  0.0273, -0.0345,  ..., -0.0346,  0.0349,  0.0238],\n",
              "          [ 0.0117,  0.0291, -0.0344,  ...,  0.0272,  0.0224, -0.0257],\n",
              "          [ 0.0293,  0.0287, -0.0169,  ...,  0.0044,  0.0262, -0.0014]],\n",
              "         requires_grad=True)),\n",
              " ('layer1.bias',\n",
              "  Parameter containing:\n",
              "  tensor([ 0.0110, -0.0319,  0.0018,  0.0006, -0.0011, -0.0099,  0.0251,  0.0085,\n",
              "           0.0307,  0.0320, -0.0138, -0.0069,  0.0318, -0.0118,  0.0154,  0.0094,\n",
              "           0.0327, -0.0164,  0.0105,  0.0156,  0.0109, -0.0280,  0.0262, -0.0343,\n",
              "          -0.0023, -0.0033,  0.0117,  0.0126,  0.0167,  0.0020,  0.0275,  0.0275,\n",
              "          -0.0184, -0.0019, -0.0192,  0.0074,  0.0297, -0.0012, -0.0223, -0.0207,\n",
              "          -0.0260,  0.0158, -0.0093,  0.0330, -0.0344, -0.0273, -0.0199,  0.0263,\n",
              "          -0.0068, -0.0263,  0.0144, -0.0320,  0.0014, -0.0015, -0.0219,  0.0116,\n",
              "           0.0075, -0.0133, -0.0144,  0.0039,  0.0171, -0.0098, -0.0323, -0.0044,\n",
              "          -0.0256, -0.0266, -0.0106,  0.0218,  0.0197,  0.0216,  0.0266,  0.0060,\n",
              "          -0.0145, -0.0356, -0.0084, -0.0072,  0.0258,  0.0132,  0.0240, -0.0209,\n",
              "           0.0051,  0.0188,  0.0027, -0.0029,  0.0205,  0.0059, -0.0086,  0.0265,\n",
              "          -0.0311, -0.0038,  0.0100, -0.0333,  0.0004, -0.0241, -0.0036, -0.0125,\n",
              "           0.0153, -0.0162, -0.0153,  0.0069], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "list(model.named_parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjmrnDXobxo",
        "outputId": "1c3de12c-a112-412a-8fab-a506de7a9774"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0119, -0.0353, -0.0085,  ..., -0.0141, -0.0006, -0.0157],\n",
              "        [-0.0288, -0.0321, -0.0197,  ..., -0.0129, -0.0137,  0.0344],\n",
              "        [ 0.0055,  0.0250, -0.0125,  ..., -0.0257, -0.0194,  0.0250],\n",
              "        ...,\n",
              "        [ 0.0042,  0.0273, -0.0345,  ..., -0.0346,  0.0349,  0.0238],\n",
              "        [ 0.0117,  0.0291, -0.0344,  ...,  0.0272,  0.0224, -0.0257],\n",
              "        [ 0.0293,  0.0287, -0.0169,  ...,  0.0044,  0.0262, -0.0014]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.get_parameter('layer1.weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cXyZlQwJca"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 3</b> - Simple Network:</span>\n",
        "\n",
        "---\n",
        "\n",
        "The above network is very simple. Implement a better version with the following layers:\n",
        "- One **linear input layer** of 300 perceptrons, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear hidden layer** of size 200, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear output layer**, with a **softmax** activation function.\n",
        "\n",
        "Assume that `torch.nn` is already imported as `nn`. Furthermore, `torch.nn.functional` is available as `F`.\n",
        "See [here](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) for documentation of the `torch.nn.Dropout` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vpYsDHgzwuwI"
      },
      "outputs": [],
      "source": [
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self, dropout:float=.2) -> None:\n",
        "        super().__init__()\n",
        "        #continue\n",
        "        self.input_layer = nn.Linear(in_features=784,out_features=300)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.hidden_layer = nn.Linear(in_features=300,out_features=200)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.output_layer = nn.Linear(in_features=200,out_features=10)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        #continue\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.hidden_layer(x))\n",
        "        x = self.dropout2(x)\n",
        "        return F.softmax(self.output_layer(x),dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yN435-5R7vM"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 3. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbQ6Z5X6_B_f"
      },
      "source": [
        "**Alternative but more restrictive:** `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "2z98s4XR_B_g"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Sequential\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP5mVGek_B_g"
      },
      "source": [
        "Unnamed layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "2FYtVeIo_B_h"
      },
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    nn.Linear(in_features=784, out_features=100, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=len(class_names), bias=True),\n",
        "    nn.Softmax(dim=-1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX5fcDoS_B_i"
      },
      "source": [
        "Named layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "YUvdvl7Z_B_j"
      },
      "outputs": [],
      "source": [
        "model = Sequential(OrderedDict([\n",
        "    ('layer1',      nn.Linear(in_features=784, out_features=100, bias=True)),\n",
        "    ('activation1', nn.ReLU()),\n",
        "    ('layer2',      nn.Linear(in_features=100, out_features=len(class_names), bias=True)),\n",
        "    ('activation2', nn.Softmax(dim=-1))\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWo7nYEYp-Wb"
      },
      "source": [
        "### Section 3: Training the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Q14ZHssu1E"
      },
      "source": [
        "In PyTorch one needs to define which device to use for computation. All tensors involved in the computation need to be on that device. The most common devices are:\n",
        "- `cpu`: any of your computer's CPUs\n",
        "- `cpu:0`:the first of your computer's CPUs\n",
        "- `cuda`: any of your computer's GPUs\n",
        "- `cuda:2`: the third GPU of you computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9HxsXGisi9T",
        "outputId": "792932ac-2b9a-4ad6-8ba7-3e7dcd6fbe42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# get gpu if available else cpu:\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "qs-4FS3uKsMZ"
      },
      "outputs": [],
      "source": [
        "# move a model or tensor to the device:\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZAZKxtFBFR"
      },
      "source": [
        "Prediction on new instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdDh74y0i7fX",
        "outputId": "5c352247-e51e-4a95-bbad-683f05494820"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10279723, 0.10202985, 0.10288162, 0.08556249, 0.10196924,\n",
              "        0.10871388, 0.10492999, 0.0934697 , 0.10683963, 0.09080637],\n",
              "       [0.09676953, 0.10114679, 0.10924636, 0.09417442, 0.11413984,\n",
              "        0.08470131, 0.08962692, 0.09221327, 0.11717305, 0.10080855],\n",
              "       [0.10503282, 0.1045026 , 0.10159139, 0.08872449, 0.11428121,\n",
              "        0.09162701, 0.09490623, 0.08370912, 0.11004595, 0.10557913]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "X_new = pt.tensor(X_test[:3], dtype=pt.float32, device=device)\n",
        "y_proba = model(X_new) # this returns a probability?\n",
        "y_proba = y_proba.detach().cpu().numpy() # to numpy\n",
        "y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU8cAN3fi99y",
        "outputId": "b6229935-9c80-4a13-d081-e6ef3f6579f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sandal', 'Bag', 'Coat'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "np.array(class_names)[np.argmax(y_proba, axis=1)] #if we want to know the class names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9wLOuG8vK_r"
      },
      "source": [
        "Instances of `torch.nn.Module` have a method `.train()` and a method `.eval()` that set the whole module (including submodules) in a training or prediction mode.\n",
        "\n",
        "This is necessary, as for example dropout layers are inactive during prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIRxMYLRqnoU"
      },
      "source": [
        "In order to train the network, we need to define a training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "FqjxNg_mDP2z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aBxz4ZXkz4hT"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  # 1. set model to train:\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      # move tensors to correct device:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      # reset all gradients to zero:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # create predictions:\n",
        "      y_pred = model(X_batch)\n",
        "\n",
        "      # calculate loss:\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "      # backpropagate loss:\n",
        "      loss.backward()\n",
        "\n",
        "      # update weights:\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "adSjw6i50L3b"
      },
      "outputs": [],
      "source": [
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  # 1. set model to eval:\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    # move tensors to correct device:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # create predictions:\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    # calculate loss:\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "  # calculate f1 score:\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "SASZ5PCXq4tr"
      },
      "outputs": [],
      "source": [
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float):\n",
        "  # instantiate optimizer:\n",
        "  optimizer = pt.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  # instantiate loss function:\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "    # train for one epoch:\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "\n",
        "    # evaluate on validation:\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    # save metrics:\n",
        "    history.append({\n",
        "      'loss_train':loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1']\n",
        "    })\n",
        "\n",
        "    # print message:\n",
        "    print(f'Epoch {i+1:d}/{epochs:d}:', *[f'{metric} = {history[-1][metric]:.2f};' for metric in history[-1]], sep='\\t')\n",
        "\n",
        "  # return history:\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08uZrmWMCmq"
      },
      "source": [
        "Fit the model for 30 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "U1VqXewrMCVQ",
        "outputId": "e26616a9-e0d6-4b4c-c141-514be5f0c33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\tloss_train = 2.29;\tloss_valid = 2.27;\tf1_valid = 0.10;\n",
            "Epoch 2/30:\tloss_train = 2.18;\tloss_valid = 2.05;\tf1_valid = 0.39;\n",
            "Epoch 3/30:\tloss_train = 1.94;\tloss_valid = 1.84;\tf1_valid = 0.54;\n",
            "Epoch 4/30:\tloss_train = 1.83;\tloss_valid = 1.79;\tf1_valid = 0.55;\n",
            "Epoch 5/30:\tloss_train = 1.79;\tloss_valid = 1.77;\tf1_valid = 0.55;\n",
            "Epoch 6/30:\tloss_train = 1.77;\tloss_valid = 1.74;\tf1_valid = 0.73;\n",
            "Epoch 7/30:\tloss_train = 1.74;\tloss_valid = 1.71;\tf1_valid = 0.73;\n",
            "Epoch 8/30:\tloss_train = 1.72;\tloss_valid = 1.70;\tf1_valid = 0.73;\n",
            "Epoch 9/30:\tloss_train = 1.71;\tloss_valid = 1.69;\tf1_valid = 0.73;\n",
            "Epoch 10/30:\tloss_train = 1.70;\tloss_valid = 1.69;\tf1_valid = 0.73;\n",
            "Epoch 11/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.73;\n",
            "Epoch 12/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.73;\n",
            "Epoch 13/30:\tloss_train = 1.68;\tloss_valid = 1.68;\tf1_valid = 0.73;\n",
            "Epoch 14/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.73;\n",
            "Epoch 15/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.73;\n",
            "Epoch 16/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.73;\n",
            "Epoch 17/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.73;\n",
            "Epoch 18/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 19/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 20/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 21/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 22/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 23/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 24/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 25/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 26/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.73;\n",
            "Epoch 27/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.73;\n",
            "Epoch 28/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.73;\n",
            "Epoch 29/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.73;\n",
            "Epoch 30/30:\tloss_train = 1.65;\tloss_valid = 1.65;\tf1_valid = 0.73;\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='epoch', ylabel='loss'>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# instantiate model and move to device:\n",
        "model = CustomNetwork().to(device)\n",
        "\n",
        "# train model:\n",
        "history = fit(model, loader_train, loader_valid, epochs=30, lr=.01)\n",
        "\n",
        "# plot history:\n",
        "history[['loss_train', 'loss_valid']].plot(xlabel='epoch', ylabel='loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qmHUt5M_nQd"
      },
      "source": [
        "**Evaluation**: `evaluate` will return the metric scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdArSMDi8BI",
        "outputId": "395da5b5-e365-4a3e-9cef-8d7c91fd0aa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.9333333333333333}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "evaluate(model, loader_test) #evaluate on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSUB0uJTPBg"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 4</b> - Improved Training:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Improve the above training loop with the following steps:\n",
        "1. replace the very basic SGD optimizer with the momentum-based [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer. Compare how the learning curves change after this step. **As ADAM is more sensitive to the learning rate, set it to `0.001` after changing the optimizer!**\n",
        "2. add a [`torch.optim.lr_scheduler.LinearLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html) scheduler (_start: `1.0*lr`, end:`0.33*lr`, over 10 epochs_).  Compare how the learning curves change after this step.\n",
        "3. add an **early stopping** functionality, that stops training when the validation loss has not improved for `patience` epochs and restores the model parameters to the ones achieving the best loss. **Use a patience of `5` to retrain the network.**\n",
        "\n",
        "**Disclaimer:** *We will not check whether you actually compare the loss curves before and after adding a specific step. But we may ask about their impact in the final exam.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9sPm0Newq4rH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "pwOaMCDSTOpS"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(X_batch)\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)\n",
        "\n",
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}\n",
        "\n",
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float, patience:int):\n",
        "  optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
        "  scheduler = pt.optim.lr_scheduler.LinearLR(\n",
        "        optimizer,\n",
        "        start_factor=1.0,\n",
        "        end_factor=0.33,\n",
        "        total_iters=10\n",
        "    )\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  best_loss = float('inf')\n",
        "  best_state_dict = None\n",
        "  no_improvement_epochs = 0\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "        loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "        metrics = evaluate(model, loader_valid, loss_fn)\n",
        "        scheduler.step()\n",
        "        current_val_loss = metrics['loss'] #validation loss\n",
        "        if current_val_loss < best_loss:\n",
        "            best_loss = current_val_loss\n",
        "            best_state_dict = model.state_dict()\n",
        "            no_improvement_epochs = 0\n",
        "        else:\n",
        "            no_improvement_epochs += 1\n",
        "\n",
        "        history.append({\n",
        "            'loss_train': loss_train,\n",
        "            'loss_valid': metrics['loss'],\n",
        "            'f1_valid': metrics['f1']\n",
        "        })\n",
        "\n",
        "        if no_improvement_epochs >= patience:\n",
        "          model.load_state_dict(best_state_dict)\n",
        "          break\n",
        "\n",
        "  return pd.DataFrame(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-hDPkRUY0R"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 4. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKm2rIvKUP2C"
      },
      "source": [
        "### Section 4: Other useful and frequently used functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4BHXYqUWBH"
      },
      "source": [
        "Save and load the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBmnCPTdaAlV"
      },
      "source": [
        "**Option 1:** `torch.save(...)` / `torch.load(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "QQIhSX16UXpR"
      },
      "outputs": [],
      "source": [
        "pt.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrmRkkvbVYqj",
        "outputId": "f1f30f44-af50-403f-912a-2329f6f8ff90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  model.pt\n",
            " extracting: model/data.pkl          \n",
            " extracting: model/byteorder         \n",
            " extracting: model/data/0            \n",
            " extracting: model/data/1            \n",
            " extracting: model/data/2            \n",
            " extracting: model/data/3            \n",
            " extracting: model/data/4            \n",
            " extracting: model/data/5            \n",
            " extracting: model/version           \n",
            " extracting: model/.data/serialization_id  \n"
          ]
        }
      ],
      "source": [
        "# this saves a zipfile!\n",
        "!unzip model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexXOBTKUZH_",
        "outputId": "9b15154d-3e4c-47e8-df13-c68f49c91c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = pt.load('model.pt', weights_only=False) # \"weights_only = True\" only loads PyTorch Tensors in the model file!\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr88yK-8Z5GY"
      },
      "source": [
        "**Option 2:** save/load state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "FsXhrkFhZ9NY"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "44MB9qujUPys"
      },
      "outputs": [],
      "source": [
        "with open('model_state_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(model.state_dict(), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CuVaeSJZgW0",
        "outputId": "83f63560-be48-409e-e77b-4df3f3d1fbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "with open('model_state_dict.pkl', 'rb') as f:\n",
        "  state_dict = pickle.load(f)\n",
        "model.load_state_dict(state_dict)\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w003CKN5R7vY"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 5</b> - Regression MLP</span>\n",
        "\n",
        "---\n",
        "\n",
        "We have created a classification model on Fashion MNIST with PyTorch. In addition, we can of course use similar PyTorch models to solve regression tasks. **How can we do that?** Which part should we change to make it work on regression tasks? That would be our last task in this lab. Based on your knowledge from the second lecture, you may be able to figure out which part you need to change.\n",
        "\n",
        "Create a regression model by adapting the PyTorch model we used above and train it on the [california housing dataset](https://nextilearn.dsv.su.se/mod/resource/view.php?id=25386 ).\n",
        "You may need to change **a loss function** and input / output layers as we no longer deal with images and classification. Feel free to use scikit-learn but we still recommend you to practice preprocessing with NumPy for your skills.\n",
        "\n",
        "**Upload the resulting predictions to NextIlearn. Your model should achieve an MSE < XXX to pass.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qforG1NGbEuq"
      },
      "source": [
        "1. Get training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpmUlavla3Py",
        "outputId": "332f36ec-3dc0-4a7f-86af-81747031056a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labels_train.csv', 'data_train.csv', 'description.md', 'data_test.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# 1.1 download https://www.google.com/url?q=https%3A%2F%2Fnextilearn.dsv.su.se%2Fmod%2Fresource%2Fview.php%3Fid%3D25386 to data.zip\n",
        "\n",
        "# 1.2 unzip data.zip\n",
        "import zipfile,os\n",
        "\n",
        "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "#os.listdir('data/task5')\n",
        "\n",
        "#!unzip data.zip\n",
        "\n",
        "# 1.3 check files:\n",
        "os.listdir('data/task5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYglS3ybCM8"
      },
      "source": [
        "2. Create Data Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "NQ_Rj925R7vY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# 2.1 load training data:\n",
        "data_train = pd.read_csv('data/task5/data_train.csv', index_col=0)\n",
        "labels_train = pd.read_csv('data/task5/labels_train.csv', index_col=0)\n",
        "\n",
        "# 2.2 load test data (no labels):\n",
        "data_test = pd.read_csv('data/task5/data_test.csv', index_col=0)\n",
        "\n",
        "#...\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(data_train)\n",
        "X_test_scaled = scaler.transform(data_test)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_scaled, labels_train.values.ravel(), test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = TensorDataset(pt.tensor(X_train, dtype=pt.float32), pt.tensor(y_train, dtype=pt.float32))\n",
        "valid_dataset = TensorDataset(pt.tensor(X_valid, dtype=pt.float32), pt.tensor(y_valid, dtype=pt.float32))\n",
        "loader_train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "loader_valid = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRz2hDYbYJ6"
      },
      "source": [
        "3. Create Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "nl0-sMfCR7vZ"
      },
      "outputs": [],
      "source": [
        "#...\n",
        "class RegressionNetwork(nn.Module):\n",
        "    def __init__(self, input_dim: int):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 128)\n",
        "        self.layer2 = nn.Linear(128, 64)\n",
        "        self.output_layer = nn.Linear(64, 1)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))  #\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.output_layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSyLqesbkYc"
      },
      "source": [
        "4. Train model on `data_train` and `labels_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_dqM_Yzyb1ho"
      },
      "outputs": [],
      "source": [
        "#...\n",
        "def epoch_func(model, loader_train, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    losses = []  # Store batch losses\n",
        "    for X_batch, y_batch in loader_train:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        y_pred = model(X_batch)  # Forward pass\n",
        "        loss = loss_fn(y_pred, y_batch)  # Compute loss\n",
        "        losses.append(loss.item())  # Store loss value\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "    return np.mean(losses)  # Return average training loss\n",
        "def evaluate_func(model, loader_valid, loss_fn):\n",
        "    model.eval()\n",
        "    losses = []  # Store batch losses\n",
        "    predictions = []  # Store predictions\n",
        "    with pt.no_grad():\n",
        "      for X_batch, y_batch in loader_valid:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
        "        y_pred = model(X_batch)  # Forward pass\n",
        "        loss = loss_fn(y_pred, y_batch)  # Compute loss\n",
        "        losses.append(loss.item())  # Store loss value\n",
        "        predictions.extend(y_pred.cpu().numpy())  # Store predictions\n",
        "    return {'loss': np.mean(losses), 'predictions': predictions}  # Return average validation loss and predictions\n",
        "\n",
        "def fit_func(model, loader_train, loader_valid, epochs, lr, patience):\n",
        "    optimizer = pt.optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n",
        "    scheduler = pt.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.33, total_iters=10)  # Learning rate scheduler\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_state_dict = None\n",
        "    no_improvement_epochs = 0\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = epoch_func(model, loader_train, optimizer, loss_fn)\n",
        "        metrics = evaluate_func(model, loader_valid, loss_fn)\n",
        "        scheduler.step()\n",
        "        val_loss = metrics['loss'] #validationloss\n",
        "        # Early stopping logic\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_state_dict = model.state_dict()\n",
        "            no_improvement_epochs = 0\n",
        "        else:\n",
        "            no_improvement_epochs += 1\n",
        "\n",
        "\n",
        "        history.append({'train_loss': train_loss, 'val_loss': val_loss})\n",
        "\n",
        "        if no_improvement_epochs >= patience:\n",
        "          model.load_state_dict(best_state_dict)\n",
        "          break\n",
        "\n",
        "    return pd.DataFrame(history)\n",
        "\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "model = RegressionNetwork(input_dim=X_train.shape[1]).to(device)\n",
        "history = fit_func(model, loader_train, loader_valid, epochs=30, lr=0.001, patience=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipIi84zb5ZR"
      },
      "source": [
        "5. Predict `data_test` and save predictions to `submission.csv`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "V_gqdJvucm2l"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with pt.no_grad():\n",
        "  X_test_tensor = pt.tensor(X_test_scaled, dtype=pt.float32).to(device)\n",
        "  predictions = model(X_test_tensor)\n",
        "\n",
        "pd.DataFrame(predictions.detach().cpu().numpy(), columns=['predictions']).to_csv('submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## remove it before submission\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Get final validation predictions\n",
        "eval_result = evaluate_func(model, loader_valid, nn.MSELoss())\n",
        "y_pred = np.array(eval_result['predictions']).ravel()\n",
        "y_true = y_valid if isinstance(y_valid, np.ndarray) else y_valid.numpy()\n",
        "\n",
        "# Compute and print metrics\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f\"📊 Final Validation MSE: {mse:.4f}\")\n",
        "print(f\"📈 Final R² Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPHMGSIsAleD",
        "outputId": "32eb095f-f477-46a6-f4b7-356de5dace5d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Final Validation MSE: 0.2883\n",
            "📈 Final R² Score: 0.7859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB-ezFJER7vZ"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 5. Upload your final predictions (the file* `submission.csv` *) to **Homework 2 - Code** on **NextIlearn***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}