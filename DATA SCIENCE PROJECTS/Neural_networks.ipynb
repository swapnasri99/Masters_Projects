{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb7Nui77r_v"
      },
      "source": [
        "# Lab 2. PyTorch models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aalcduo8_B-M"
      },
      "source": [
        "---\n",
        "\n",
        "How to Use This Notebook\n",
        "---\n",
        "\n",
        "**Recommended Setup**\n",
        "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
        "- In Colab, **enable GPU support** by going to:  \n",
        "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
        "\n",
        "\n",
        "**Homework Tasks**\n",
        "\n",
        " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > ```Your code ....```\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > *End of Task X.* [*Instructions for passing*]\n",
        "\n",
        " - For each task:\n",
        "   - **Complete the code** where indicated.\n",
        "   - **Upload the required results** from each task to **Homework 2 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        " - Once you've finished all the tasks:\n",
        "   Submit your **entire completed notebook (including your code!)** to **Homework 2 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        "**Important:**  \n",
        "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIH0AWH2_jxD"
      },
      "source": [
        "This lab will teach how to use PyTorch by making a simple neural network model. Regradless of model's complexity, creating any model can be completed in a similar way. We will use the **Fashion MNIST** dataset, one of the variants of the MNIST dataset. It has the same property as a normal MNIST, with the same size (28*28) and the same number of classes (10), but the images represent fashion items rather than handwritten digits, which means it might have more complexity than normal MNIST.\n",
        "\n",
        "Because of its complexity in each class, the problem is significantly more challenging than normal MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST. Below is an example of Fashion MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gQUsFpCD0aP"
      },
      "source": [
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBXx3rp8D2Nm"
      },
      "source": [
        "\n",
        "In today's lab, we will first try to create a simple fully connected network model and check its basic performance on Fashion MNIST.\n",
        "\n",
        "Based on your local machine's performance, the task might take a long time, so it is recommended to use the [Google Colab](https://colab.research.google.com/) since it can handle the lab contents with no processing bottleneck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ChFhB0bauM"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiDj5c8beHt"
      },
      "source": [
        "- Import PyTorch and load a sample dataset\n",
        "- Sequential fully connected network\n",
        "- Other useful functions (Saving/Loading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDXwomm0bxug"
      },
      "source": [
        "### Section 1: Import PyTorch and load a sample dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9hfGXIA6Ek"
      },
      "source": [
        "You should be able to install PyTorch by using `pip`. You do not need to specify a GPU version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jzUBH9xhn0JL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y7mgvEN8mtN6"
      },
      "outputs": [],
      "source": [
        "import torch as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I8zL6JdKIasB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1Ek6pMT_pdg_",
        "outputId": "9e54acce-77aa-48ee-9ae1-ac3c05d06930"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# version?\n",
        "pt.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhFeXn8MgFT2"
      },
      "source": [
        "We will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data available in github, which has 70,000 article images. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Since it is on github we can simple get it by using `git clone [repo] [folder]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McfKi-cJn0JP",
        "outputId": "cd82ff85-ce6d-48a0-fa95-a831bb7764fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 762, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 762 (delta 0), reused 2 (delta 0), pack-reused 758 (from 1)\u001b[K\n",
            "Receiving objects: 100% (762/762), 105.85 MiB | 45.43 MiB/s, done.\n",
            "Resolving deltas: 100% (444/444), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zalandoresearch/fashion-mnist data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6efgvJL-WwWu"
      },
      "source": [
        "#### Dataset handling: Traditional way with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lga5zwx6BJti"
      },
      "source": [
        "Datasets can be found in diverse locations -- e.g. on [github](https://github.com/), [zenodo](https://zenodo.org/), [huggingface](https://huggingface.co/docs/hub/en/datasets), [kaggle](https://www.kaggle.com/datasets) or **your companies server**. Some Python modules like `torch` and `tensorflow` also have their own easy-to-use versions of standard datasets specialised to the specific library. For a fast, but less general alternative to this tutorial, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). **The linked tutorial is for interrested students and not part of this assignment!**\n",
        "\n",
        "If the dataset is hosted on github or similar, the first step is to check the description: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist#get-the-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SSWdpC1tjnL"
      },
      "source": [
        "Lets check out the `mnist_reader` they mention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYgIPJnr4Cz",
        "outputId": "afa7c10c-7910-444b-ea20-441c8b2827c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def load_mnist(path, kind='train'):\n",
            "    import os\n",
            "    import gzip\n",
            "    import numpy as np\n",
            "\n",
            "    \"\"\"Load MNIST data from `path`\"\"\"\n",
            "    labels_path = os.path.join(path,\n",
            "                               '%s-labels-idx1-ubyte.gz'\n",
            "                               % kind)\n",
            "    images_path = os.path.join(path,\n",
            "                               '%s-images-idx3-ubyte.gz'\n",
            "                               % kind)\n",
            "\n",
            "    with gzip.open(labels_path, 'rb') as lbpath:\n",
            "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
            "                               offset=8)\n",
            "\n",
            "    with gzip.open(images_path, 'rb') as imgpath:\n",
            "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
            "                               offset=16).reshape(len(labels), 784)\n",
            "\n",
            "    return images, labels\n"
          ]
        }
      ],
      "source": [
        "!cat data/utils/mnist_reader.py # linux / mac\n",
        "#!type data\\utils\\mnist_reader.py # windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-Nz93XtsRy"
      },
      "source": [
        "What values does the parameter `kind` take?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXvbQYytQfW",
        "outputId": "fede1d25-6b5e-49cf-eea3-89e61c68cf6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train-images-idx3-ubyte.gz',\n",
              " 't10k-images-idx3-ubyte.gz',\n",
              " 't10k-labels-idx1-ubyte.gz',\n",
              " 'train-labels-idx1-ubyte.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('data/data/fashion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsK-umdt4pc"
      },
      "source": [
        "Let's load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_i0BcD_qwx0"
      },
      "outputs": [],
      "source": [
        "# import mnist_reader:\n",
        "import data.utils.mnist_reader as mnist_reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g2DoMiOnplgm"
      },
      "outputs": [],
      "source": [
        "# load data:\n",
        "X_train_full, y_train_full = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "X_test, y_test = mnist_reader.load_mnist('data/data/fashion', kind='t10k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KfXaFeBQLY"
      },
      "source": [
        "This dataset is loaded as a NumPy array which we learned before in Lab 1. You can use all the methods you learned to check the properties of the dataset, like **shape** or **describe**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQGzWUZABSdD",
        "outputId": "5fd39a3f-4e5c-44ff-f2e9-306f76b35b85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# type?\n",
        "type(X_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA4f__FUppwQ",
        "outputId": "99c3fffb-4c1b-4a23-9d0d-d4cf8807272a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# shape?\n",
        "X_train_full.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRWMKbUZnJJ",
        "outputId": "2293b8dc-b11d-4091-96f3-6bcfcb58b24f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "np.unique(y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSk4-jABU95"
      },
      "source": [
        "As the dataset is composed of grayscale pixels, the datatype of it is unsigned integer. The dataset also has a pixed range [0, 255] so it does not need to take higher bit than 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdNJONOHptj6",
        "outputId": "d9e5d343-0b55-4521-a47a-1aaa541f8783"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# dtype?\n",
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZE6WfngbYs"
      },
      "source": [
        "Besides that, PyTorch models are also usually evaluated by one more separate set called validation set as training is an iterative and time-consuming process and we do not know when we need to stop clearly. So we would like to estimate the right time to interrupt the training process by checking its performance for each iteration.\n",
        "\n",
        "To create a validation set, there can be many options, we can explicitly split the dataset using index, or we can just use a training set but with the option stating we want to validate, when we actually fit the model. However, this time we will use scikit-learn's `train_test_split` method to create a validation set as it can provide a nice stratification option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUEmqGNGoZ_W"
      },
      "source": [
        "We need a simiple normalization - as we all know the graysclae ranges from 0 to 255..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lb6n6PzLgjRj"
      },
      "outputs": [],
      "source": [
        "# Introduced in the coursebook\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "azOEHFspR7u5"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtvJAWxvhEP"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 1</b> - Stratified Split:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Replace the above simple training/validation split with a **stratified** one (50% train, 50% validation):\n",
        "  - Use `X_train_full` and `y_train_full`\n",
        "  - Enable `shuffle` and `stratification`\n",
        "\n",
        "Use [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Print and check their shapes afterward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yQuXXouFLDRN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# normalize:\n",
        "X_train_full = X_train_full / 255.\n",
        "\n",
        "# split data:\n",
        "X_train, X_valid, y_train, y_valid =train_test_split(X_train_full,y_train_full,train_size=0.5,shuffle=True,stratify = y_train_full) #continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r4gVzDXcR7u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8c2c5a-11d6-41f9-eae4-193ece62a10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 784)\n",
            "(30000, 784)\n",
            "(30000,)\n",
            "(30000,)\n"
          ]
        }
      ],
      "source": [
        "# shape?\n",
        "#continue\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_f0SkwQR7u7"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 1. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTSsrnEF2XC"
      },
      "source": [
        "Here we prepared the class names of the fashion MNIST dataset for your convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vRc7tKoIsFx4"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eBOMMsxAxrfj",
        "outputId": "ecbe2004-ab2c-476c-fc1a-cc6a25b9c73a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T-shirt/top'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Use the numeric label to get the class name, e.g:\n",
        "class_names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch49P29iEDxC"
      },
      "source": [
        "We can also try to see each data instance by using **plt.imshow**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FSwEtbA6KmFg",
        "outputId": "3a66129a-7310-4f5c-fd8c-1ffd2737da01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = np.random.randint(0, X_train.shape[0])\n",
        "plt.imshow(X_train[i].reshape((28, 28)), cmap='gray') # cmap to make it recognize grayscale\n",
        "plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPR-OZKyStX"
      },
      "source": [
        "#### Optimizing memory consuption using pipelines:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w2ohRDo2eW"
      },
      "source": [
        "Imagine taking the above approach with very large datasets (e.g. used for training modern LLMs). Loading all the data before training would exceed RAM and VRAM of almost any computer.\n",
        "\n",
        "Therefore, we are going to use the [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) API:\n",
        "\n",
        "---\n",
        "***An abstract class representing a Dataset.***\n",
        "\n",
        "*All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite* `__getitem__()`*, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite* `__len__()`*, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader. Subclasses could also optionally implement* `__getitems__()`*, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xcvyxGDerVFS"
      },
      "outputs": [],
      "source": [
        "from numpy.typing import NDArray\n",
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, X:NDArray[np.int8], y:NDArray[np.int8]) -> None:\n",
        "    # normalize:\n",
        "    self.X = X.astype(np.float32) / 255.0\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "\n",
        "    # load data:\n",
        "    train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "    t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "    data   = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "    labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "    # split data:\n",
        "    n = len(labels)\n",
        "    n_train = int(n * fraction_train)\n",
        "    n_validation = int(n * fraction_validation)\n",
        "\n",
        "    data_train = FashionMNIST(\n",
        "        data[:n_train],\n",
        "        labels[:n_train]\n",
        "    )\n",
        "    data_valid = FashionMNIST(\n",
        "        data[n_train:n_train+n_validation],\n",
        "        labels[n_train:n_train+n_validation]\n",
        "    )\n",
        "    data_test = FashionMNIST(\n",
        "        data[n_train+n_validation:],\n",
        "        labels[n_train+n_validation:]\n",
        "    )\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0v0JjVOk57s"
      },
      "source": [
        "It works like a list of tuples `(X, y)` in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SCOTVO81lZyD"
      },
      "outputs": [],
      "source": [
        "data, _, _ = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjOC4aIlpfp",
        "outputId": "b88854d5-d4fc-4e3b-d2cb-f6bdaa8c0b7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# call to __len__:\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFLbrYUlrdL",
        "outputId": "b1b19222-ad79-4157-cf11-61438a3ae497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
              "        0.34509805, 0.7372549 , 0.6745098 , 0.5176471 , 0.49019608,\n",
              "        0.5529412 , 0.78039217, 0.56078434, 0.03529412, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.07843138,\n",
              "        0.5137255 , 0.78039217, 0.80784315, 0.76862746, 0.7921569 ,\n",
              "        0.9490196 , 1.        , 1.        , 0.98039216, 0.87058824,\n",
              "        0.77254903, 0.80784315, 0.7372549 , 0.49411765, 0.06666667,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.13725491, 0.8392157 , 0.7490196 , 0.7176471 ,\n",
              "        0.69803923, 0.6862745 , 0.65882355, 0.5882353 , 0.63529414,\n",
              "        0.62352943, 0.59607846, 0.61960787, 0.7019608 , 0.7176471 ,\n",
              "        0.7411765 , 0.7647059 , 0.7254902 , 0.32156864, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
              "        0.74509805, 0.6745098 , 0.69411767, 0.6901961 , 0.67058825,\n",
              "        0.6627451 , 0.63529414, 0.60784316, 0.5803922 , 0.6039216 ,\n",
              "        0.6627451 , 0.68235296, 0.6862745 , 0.6862745 , 0.69411767,\n",
              "        0.7176471 , 0.7372549 , 0.04705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09803922, 0.7607843 , 0.7058824 , 0.69803923,\n",
              "        0.68235296, 0.72156864, 0.73333335, 0.7411765 , 0.73333335,\n",
              "        0.72156864, 0.70980394, 0.7411765 , 0.78431374, 0.77254903,\n",
              "        0.75686276, 0.74509805, 0.69803923, 0.6862745 , 0.7607843 ,\n",
              "        0.3529412 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.16470589,\n",
              "        0.85490197, 0.7490196 , 0.77254903, 0.8156863 , 0.8       ,\n",
              "        0.827451  , 0.81960785, 0.8235294 , 0.83137256, 0.827451  ,\n",
              "        0.8392157 , 0.84313726, 0.8352941 , 0.8392157 , 0.827451  ,\n",
              "        0.827451  , 0.7490196 , 0.78431374, 0.61960787, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34509805, 0.8666667 , 0.84313726,\n",
              "        0.8509804 , 0.85882354, 0.827451  , 0.7254902 , 0.5882353 ,\n",
              "        0.4627451 , 0.41960785, 0.3882353 , 0.34509805, 0.3254902 ,\n",
              "        0.3529412 , 0.5294118 , 0.83137256, 0.79607844, 0.8117647 ,\n",
              "        0.85882354, 0.6627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10588235, 0.4627451 , 0.63529414, 0.15686275,\n",
              "        0.        , 0.        , 0.        , 0.03921569, 0.07450981,\n",
              "        0.10980392, 0.15294118, 0.18431373, 0.14117648, 0.        ,\n",
              "        0.        , 0.79607844, 0.9019608 , 0.8627451 , 0.79607844,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.5411765 , 0.53333336,\n",
              "        0.2784314 , 0.27058825, 0.21176471, 0.84705883, 0.8509804 ,\n",
              "        0.79607844, 0.72156864, 0.65882355, 0.6392157 , 0.63529414,\n",
              "        0.6392157 , 0.69803923, 0.8666667 , 0.7294118 , 0.14901961,\n",
              "        0.10196079, 0.02745098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2627451 , 0.5254902 , 0.6039216 , 0.8784314 ,\n",
              "        0.5058824 , 0.25882354, 0.31764707, 0.45882353, 0.5058824 ,\n",
              "        0.5019608 , 0.5176471 , 0.5372549 , 0.5137255 , 0.5058824 ,\n",
              "        0.3372549 , 0.28627452, 0.6156863 , 0.5921569 , 0.5254902 ,\n",
              "        0.84705883, 0.07058824, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.79607844,\n",
              "        0.7764706 , 0.6745098 , 0.7176471 , 0.80784315, 1.        ,\n",
              "        1.        , 0.98039216, 0.9529412 , 0.9411765 , 0.9372549 ,\n",
              "        0.92156863, 0.93333334, 0.95686275, 1.        , 0.93333334,\n",
              "        0.72156864, 0.627451  , 0.3372549 , 0.38431373, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.47843137, 0.7372549 , 0.8784314 ,\n",
              "        0.5921569 , 0.4117647 , 0.49803922, 0.38039216, 0.39215687,\n",
              "        0.4117647 , 0.44705883, 0.45882353, 0.45882353, 0.44313726,\n",
              "        0.40392157, 0.38431373, 0.43529412, 0.5568628 , 0.99607843,\n",
              "        0.7490196 , 1.        , 0.19215687, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.6392157 , 0.7019608 , 0.78431374, 0.37254903, 0.6039216 ,\n",
              "        0.7764706 , 0.77254903, 0.78431374, 0.78431374, 0.7764706 ,\n",
              "        0.77254903, 0.7764706 , 0.78039217, 0.7921569 , 0.78431374,\n",
              "        0.6901961 , 0.3372549 , 0.80784315, 0.6156863 , 0.63529414,\n",
              "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.77254903, 0.7882353 ,\n",
              "        0.8980392 , 0.2784314 , 0.5647059 , 0.7607843 , 0.70980394,\n",
              "        0.7176471 , 0.7019608 , 0.7137255 , 0.7058824 , 0.7019608 ,\n",
              "        0.7058824 , 0.74509805, 0.7254902 , 0.77254903, 0.29803923,\n",
              "        0.85882354, 0.7254902 , 0.7882353 , 0.13333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.78039217, 0.75686276, 0.8862745 , 0.22745098,\n",
              "        0.6039216 , 0.7529412 , 0.72156864, 0.73333335, 0.72156864,\n",
              "        0.7294118 , 0.72156864, 0.7254902 , 0.7176471 , 0.7529412 ,\n",
              "        0.7490196 , 0.78431374, 0.21960784, 0.85882354, 0.79607844,\n",
              "        0.8117647 , 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.7882353 ,\n",
              "        0.7607843 , 0.8784314 , 0.16078432, 0.6392157 , 0.74509805,\n",
              "        0.7294118 , 0.7294118 , 0.72156864, 0.7254902 , 0.7176471 ,\n",
              "        0.7254902 , 0.69803923, 0.74509805, 0.7607843 , 0.7921569 ,\n",
              "        0.12941177, 0.827451  , 0.78431374, 0.80784315, 0.28627452,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.7882353 , 0.77254903, 0.87058824,\n",
              "        0.06666667, 0.6745098 , 0.74509805, 0.7294118 , 0.73333335,\n",
              "        0.7137255 , 0.7294118 , 0.7254902 , 0.73333335, 0.7058824 ,\n",
              "        0.73333335, 0.75686276, 0.7921569 , 0.10196079, 0.83137256,\n",
              "        0.7921569 , 0.79607844, 0.29803923, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.78431374, 0.77254903, 0.8745098 , 0.        , 0.69411767,\n",
              "        0.7411765 , 0.72156864, 0.7254902 , 0.69803923, 0.72156864,\n",
              "        0.7176471 , 0.72156864, 0.7058824 , 0.7176471 , 0.7411765 ,\n",
              "        0.79607844, 0.13725491, 0.76862746, 0.79607844, 0.79607844,\n",
              "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.78431374, 0.77254903,\n",
              "        0.8745098 , 0.        , 0.7254902 , 0.73333335, 0.7254902 ,\n",
              "        0.73333335, 0.7058824 , 0.72156864, 0.7137255 , 0.7176471 ,\n",
              "        0.69803923, 0.7137255 , 0.7176471 , 0.8039216 , 0.17254902,\n",
              "        0.62352943, 0.8117647 , 0.7882353 , 0.33333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.73333335, 0.7764706 , 0.88235295, 0.        ,\n",
              "        0.7607843 , 0.7372549 , 0.72156864, 0.7254902 , 0.7058824 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.70980394, 0.70980394,\n",
              "        0.69411767, 0.80784315, 0.18039216, 0.5058824 , 0.827451  ,\n",
              "        0.78431374, 0.34509805, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.7294118 ,\n",
              "        0.78431374, 0.827451  , 0.        , 0.78039217, 0.7411765 ,\n",
              "        0.72156864, 0.72156864, 0.7254902 , 0.7137255 , 0.7176471 ,\n",
              "        0.72156864, 0.7254902 , 0.7137255 , 0.6862745 , 0.8039216 ,\n",
              "        0.19607843, 0.38039216, 0.84705883, 0.77254903, 0.3647059 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.7254902 , 0.8       , 0.72156864,\n",
              "        0.        , 0.7921569 , 0.7372549 , 0.7137255 , 0.7137255 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.7137255 , 0.7058824 ,\n",
              "        0.7137255 , 0.68235296, 0.7921569 , 0.24705882, 0.23137255,\n",
              "        0.8627451 , 0.76862746, 0.36862746, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
              "        0.72156864, 0.80784315, 0.6156863 , 0.        , 0.8       ,\n",
              "        0.73333335, 0.73333335, 0.7411765 , 0.7529412 , 0.74509805,\n",
              "        0.74509805, 0.7490196 , 0.74509805, 0.73333335, 0.7176471 ,\n",
              "        0.7921569 , 0.30588236, 0.13725491, 0.87058824, 0.77254903,\n",
              "        0.37254903, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01960784, 0.7176471 , 0.8156863 ,\n",
              "        0.49803922, 0.        , 0.77254903, 0.6509804 , 0.6       ,\n",
              "        0.58431375, 0.58431375, 0.57254905, 0.5803922 , 0.58431375,\n",
              "        0.5882353 , 0.5921569 , 0.61960787, 0.7490196 , 0.3529412 ,\n",
              "        0.03137255, 0.8745098 , 0.7647059 , 0.3882353 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.72156864, 0.8156863 , 0.44705883, 0.        ,\n",
              "        0.8       , 0.6784314 , 0.6313726 , 0.7058824 , 0.6901961 ,\n",
              "        0.6745098 , 0.6784314 , 0.6784314 , 0.68235296, 0.6901961 ,\n",
              "        0.63529414, 0.7921569 , 0.4509804 , 0.        , 0.8980392 ,\n",
              "        0.78039217, 0.4117647 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03529412, 0.69803923,\n",
              "        0.8       , 0.4509804 , 0.        , 0.4745098 , 0.5294118 ,\n",
              "        0.44705883, 0.45882353, 0.44705883, 0.44705883, 0.45882353,\n",
              "        0.4627451 , 0.46666667, 0.45882353, 0.44313726, 0.5764706 ,\n",
              "        0.24705882, 0.        , 0.88235295, 0.76862746, 0.41960785,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.7058824 , 0.80784315, 0.5137255 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.8784314 , 0.77254903, 0.48235294, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5529412 , 0.5921569 , 0.29803923, 0.        , 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.52156866, 0.654902  ,\n",
              "        0.28627452, 0.        , 0.        , 0.        ], dtype=float32),\n",
              " np.uint8(2))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# call to __getitem__:\n",
        "data[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1u-U7X-fXCB"
      },
      "source": [
        "But the above implementation still loads everything at the time of instantiation of the `FashionMNIST` class. So let's transform the data into a format that you see more often with big datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EADlbbqB01Kw"
      },
      "outputs": [],
      "source": [
        "# unzip data:\n",
        "target_dir = 'data/data/fashion/unzipped'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "data = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "for i, x in enumerate(data):\n",
        "  file = os.path.join(target_dir, f'img_{i:d}.npy')\n",
        "  with open(file, 'wb') as f:\n",
        "    np.save(f, x.reshape((28, 28)))\n",
        "\n",
        "with open(os.path.join(target_dir, 'labels.npy'), 'wb') as f:\n",
        "  np.save(f, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0YptsZ-QaG",
        "outputId": "19894b8e-8b20-4669-f493-4dfbd33a3dbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_60194.npy',\n",
              " 'img_28702.npy',\n",
              " 'img_45573.npy',\n",
              " 'img_31699.npy',\n",
              " 'img_16050.npy',\n",
              " 'img_13862.npy',\n",
              " 'img_29405.npy',\n",
              " 'img_4588.npy',\n",
              " 'img_841.npy',\n",
              " 'img_39316.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "os.listdir(target_dir)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrICJqXvjc1Y"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 2</b> - Dataset:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following class.\n",
        "- It should load every single sample dynamically from disk when it is requested and this way keep memory consumption to a minimum.\n",
        "- Use your code from Task 1 to create stratified splits using the `stratify` and `shuffle` arguments of `create_split`.\n",
        "- Use the variable `target_dir` as the path to the unzipped data.\n",
        "- **Make sure it produces the the right type of outputs (see type hintig and class above)!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VmiKviaXkHYb"
      },
      "outputs": [],
      "source": [
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, indices:NDArray[np.int32], labels:NDArray[np.int8]) -> None:\n",
        "    self.indices = indices\n",
        "    self.labels  = labels\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.indices)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    # complete\n",
        "    index = self.indices[idx]\n",
        "    label = self.labels[idx]\n",
        "    file_path = os.path.join(target_dir,f'img_{index}.npy')\n",
        "    image = np.load(file_path).astype(np.float32).reshape(-1)/255.0\n",
        "    return image,label\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float, stratify:bool=True, shuffle:bool=True) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "    # complete\n",
        "    labels_file = os.path.join(target_dir,'labels.npy')\n",
        "    labels = np.load(labels_file)\n",
        "    indices = np.arange(len(labels))\n",
        "\n",
        "    train_indices,temp_indices,y_train,y_temp = train_test_split(indices,labels,train_size=fraction_train,shuffle=shuffle,stratify=labels if stratify else None)\n",
        "\n",
        "    fraction_remaining = fraction_validation + fraction_test\n",
        "    fraction_val_new = fraction_validation/fraction_remaining\n",
        "\n",
        "    valid_indices,test_indices,y_valid,y_test = train_test_split(temp_indices,y_temp,train_size=fraction_val_new,shuffle=shuffle,stratify=y_temp if stratify else None)\n",
        "\n",
        "    data_train = FashionMNIST(train_indices,y_train)\n",
        "    data_valid = FashionMNIST(valid_indices,y_valid)\n",
        "    data_test = FashionMNIST(test_indices,y_test)\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxU6CLfR7vD"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 2. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRzLUn4kGGVU"
      },
      "source": [
        "Our objective is to create a model with the high accuracy on this dataset. Let's start to create our first model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ox0oodObDPH"
      },
      "source": [
        "**Shuffling and batching**: Using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), you can easily shuffle and batch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QdYJGAsARQxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BZmqQ9W2pp5b"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid, data_test = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W2dJNcKrESEU"
      },
      "outputs": [],
      "source": [
        "loader_train = DataLoader(data_train,             # dataset from which to load the data.\n",
        "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1).\n",
        "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False).\n",
        "                          sampler=None,           # defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented.\n",
        "                                                  # If specified, shuffle must not be specified.\n",
        "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
        "                          drop_last=False)        # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
        "                                                  # If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Tj964nU9EVbq"
      },
      "outputs": [],
      "source": [
        "# validation set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_valid = DataLoader(data_valid,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nu56t0MPO1PF"
      },
      "outputs": [],
      "source": [
        "# test set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_test  = DataLoader(data_test,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewz-SbwJxZ1t"
      },
      "source": [
        "### Section 2: Sequential fully connected network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fh7PjMWqOnS"
      },
      "source": [
        "#### Instantiating the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuxZ7HZgpwm"
      },
      "source": [
        "The standard way to create a PyTorch model is to override the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. To create a model you need to override the following methods:\n",
        "- `__init__(self, ...) -> None`: Initializes the module and instantiates all the layers and functions.\n",
        "- `forward(self, x) -> y`: implements the forward pass through the network.\n",
        "\n",
        "When you create a layer (e.g. [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)), you should specify **in_features** and **out_features**. Don't forget to apply an **activation function** in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dpDMjCbExvzN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(in_features=784, out_features=100, bias=True)\n",
        "        self.layer2 = nn.Linear(in_features=100, out_features=len(class_names), bias=True)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        x = F.relu(self.layer1(x))\n",
        "        return F.softmax(self.layer2(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvjomL9CJcrr"
      },
      "source": [
        "We can visualize the model using **keras.utils.plot_model**. It helps to figue out (or validate) the structure of complete models having multiple paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iLn73SNJenS",
        "outputId": "5ca225df-b447-456d-dac7-644a5287d161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CustomNetwork()\n",
        "summary(model, input_size=(784,), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_iVtGfSEe7b"
      },
      "source": [
        "Summarization of model parameters is only possible when the model has an input information as it needs to calculate the fully connected parameters from the input layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEOcLYKLEpgw"
      },
      "source": [
        "A model instance has various attributes to get layers, weights - which are just for your reference to check the real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5iYpVqcwYL9",
        "outputId": "455935c9-a9c5-4249-ab9c-43a118789694"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=100, bias=True),\n",
              " Linear(in_features=100, out_features=10, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# You can get a generator object of properties of type `torch.nn.Module` using `children()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwCNTJ4nGyW",
        "outputId": "b19515c4-c404-4f37-f0b3-ad41c74cb378"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "list(model.named_children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJcb7xZtpEAZ",
        "outputId": "1e6b7d9f-2b34-43b2-b61c-57c8f29ea5a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=100, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.get_submodule('layer1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnS08_Lom1s",
        "outputId": "494395ac-1128-4496-ff91-ec5760eb5bb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  CustomNetwork(\n",
              "    (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
              "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )),\n",
              " ('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# All modules in the model (including itself):\n",
        "list(model.named_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAa1OQuPnlNF",
        "outputId": "eb3df5ec-c44f-4df0-ff25-1a692701a21d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0333, -0.0285,  0.0030,  ..., -0.0345, -0.0003,  0.0132],\n",
              "         [-0.0039, -0.0040, -0.0271,  ...,  0.0217,  0.0090, -0.0046],\n",
              "         [ 0.0179, -0.0291, -0.0311,  ..., -0.0044, -0.0035, -0.0236],\n",
              "         ...,\n",
              "         [ 0.0079,  0.0173, -0.0270,  ..., -0.0156,  0.0190,  0.0236],\n",
              "         [-0.0096,  0.0044,  0.0230,  ...,  0.0008,  0.0291,  0.0128],\n",
              "         [ 0.0313, -0.0063, -0.0144,  ...,  0.0294,  0.0061, -0.0344]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0294, -0.0200, -0.0196, -0.0247,  0.0077, -0.0074, -0.0290,  0.0027,\n",
              "          0.0318, -0.0322,  0.0145, -0.0096, -0.0267,  0.0133, -0.0313, -0.0135,\n",
              "          0.0356,  0.0111,  0.0230,  0.0304, -0.0070, -0.0094, -0.0065, -0.0294,\n",
              "          0.0166,  0.0348,  0.0311, -0.0073, -0.0277,  0.0187,  0.0131, -0.0199,\n",
              "          0.0116,  0.0128, -0.0197,  0.0035,  0.0141, -0.0054, -0.0208, -0.0235,\n",
              "          0.0296, -0.0245, -0.0023, -0.0239,  0.0057, -0.0284,  0.0085,  0.0250,\n",
              "          0.0160, -0.0011, -0.0172,  0.0244,  0.0340,  0.0229, -0.0003, -0.0240,\n",
              "          0.0119,  0.0041, -0.0159, -0.0355, -0.0069, -0.0204,  0.0242, -0.0251,\n",
              "          0.0086, -0.0190, -0.0351,  0.0287,  0.0200, -0.0190, -0.0304,  0.0343,\n",
              "         -0.0224, -0.0257,  0.0014, -0.0344, -0.0269, -0.0115, -0.0185,  0.0141,\n",
              "         -0.0120,  0.0287, -0.0210, -0.0179, -0.0119,  0.0244,  0.0353, -0.0123,\n",
              "          0.0031, -0.0343,  0.0286, -0.0356,  0.0219,  0.0125,  0.0059, -0.0026,\n",
              "         -0.0325, -0.0337, -0.0050,  0.0188], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# You can get a generator object of parameters (weights) for each submodule using `parameters()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUW334iaoA7z",
        "outputId": "dd44c16c-bcae-4ef2-883b-a39e94402c3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.0333, -0.0285,  0.0030,  ..., -0.0345, -0.0003,  0.0132],\n",
              "          [-0.0039, -0.0040, -0.0271,  ...,  0.0217,  0.0090, -0.0046],\n",
              "          [ 0.0179, -0.0291, -0.0311,  ..., -0.0044, -0.0035, -0.0236],\n",
              "          ...,\n",
              "          [ 0.0079,  0.0173, -0.0270,  ..., -0.0156,  0.0190,  0.0236],\n",
              "          [-0.0096,  0.0044,  0.0230,  ...,  0.0008,  0.0291,  0.0128],\n",
              "          [ 0.0313, -0.0063, -0.0144,  ...,  0.0294,  0.0061, -0.0344]],\n",
              "         requires_grad=True)),\n",
              " ('layer1.bias',\n",
              "  Parameter containing:\n",
              "  tensor([-0.0294, -0.0200, -0.0196, -0.0247,  0.0077, -0.0074, -0.0290,  0.0027,\n",
              "           0.0318, -0.0322,  0.0145, -0.0096, -0.0267,  0.0133, -0.0313, -0.0135,\n",
              "           0.0356,  0.0111,  0.0230,  0.0304, -0.0070, -0.0094, -0.0065, -0.0294,\n",
              "           0.0166,  0.0348,  0.0311, -0.0073, -0.0277,  0.0187,  0.0131, -0.0199,\n",
              "           0.0116,  0.0128, -0.0197,  0.0035,  0.0141, -0.0054, -0.0208, -0.0235,\n",
              "           0.0296, -0.0245, -0.0023, -0.0239,  0.0057, -0.0284,  0.0085,  0.0250,\n",
              "           0.0160, -0.0011, -0.0172,  0.0244,  0.0340,  0.0229, -0.0003, -0.0240,\n",
              "           0.0119,  0.0041, -0.0159, -0.0355, -0.0069, -0.0204,  0.0242, -0.0251,\n",
              "           0.0086, -0.0190, -0.0351,  0.0287,  0.0200, -0.0190, -0.0304,  0.0343,\n",
              "          -0.0224, -0.0257,  0.0014, -0.0344, -0.0269, -0.0115, -0.0185,  0.0141,\n",
              "          -0.0120,  0.0287, -0.0210, -0.0179, -0.0119,  0.0244,  0.0353, -0.0123,\n",
              "           0.0031, -0.0343,  0.0286, -0.0356,  0.0219,  0.0125,  0.0059, -0.0026,\n",
              "          -0.0325, -0.0337, -0.0050,  0.0188], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "list(model.named_parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjmrnDXobxo",
        "outputId": "a7a08237-fada-4779-972d-21be71e9db64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0333, -0.0285,  0.0030,  ..., -0.0345, -0.0003,  0.0132],\n",
              "        [-0.0039, -0.0040, -0.0271,  ...,  0.0217,  0.0090, -0.0046],\n",
              "        [ 0.0179, -0.0291, -0.0311,  ..., -0.0044, -0.0035, -0.0236],\n",
              "        ...,\n",
              "        [ 0.0079,  0.0173, -0.0270,  ..., -0.0156,  0.0190,  0.0236],\n",
              "        [-0.0096,  0.0044,  0.0230,  ...,  0.0008,  0.0291,  0.0128],\n",
              "        [ 0.0313, -0.0063, -0.0144,  ...,  0.0294,  0.0061, -0.0344]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.get_parameter('layer1.weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cXyZlQwJca"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 3</b> - Simple Network:</span>\n",
        "\n",
        "---\n",
        "\n",
        "The above network is very simple. Implement a better version with the following layers:\n",
        "- One **linear input layer** of 300 perceptrons, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear hidden layer** of size 200, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear output layer**, with a **softmax** activation function.\n",
        "\n",
        "Assume that `torch.nn` is already imported as `nn`. Furthermore, `torch.nn.functional` is available as `F`.\n",
        "See [here](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) for documentation of the `torch.nn.Dropout` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vpYsDHgzwuwI"
      },
      "outputs": [],
      "source": [
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self, dropout:float=.2) -> None:\n",
        "        super().__init__()\n",
        "        #continue\n",
        "        self.input_layer = nn.Linear(in_features=784,out_features=300)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.hidden_layer = nn.Linear(in_features=300,out_features=200)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.output_layer = nn.Linear(in_features=200,out_features=10)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        #continue\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.hidden_layer(x))\n",
        "        x = self.dropout2(x)\n",
        "        return F.softmax(self.output_layer(x),dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yN435-5R7vM"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 3. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbQ6Z5X6_B_f"
      },
      "source": [
        "**Alternative but more restrictive:** `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "2z98s4XR_B_g"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Sequential\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP5mVGek_B_g"
      },
      "source": [
        "Unnamed layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "2FYtVeIo_B_h"
      },
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    nn.Linear(in_features=784, out_features=100, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=len(class_names), bias=True),\n",
        "    nn.Softmax(dim=-1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX5fcDoS_B_i"
      },
      "source": [
        "Named layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "YUvdvl7Z_B_j"
      },
      "outputs": [],
      "source": [
        "model = Sequential(OrderedDict([\n",
        "    ('layer1',      nn.Linear(in_features=784, out_features=100, bias=True)),\n",
        "    ('activation1', nn.ReLU()),\n",
        "    ('layer2',      nn.Linear(in_features=100, out_features=len(class_names), bias=True)),\n",
        "    ('activation2', nn.Softmax(dim=-1))\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWo7nYEYp-Wb"
      },
      "source": [
        "### Section 3: Training the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Q14ZHssu1E"
      },
      "source": [
        "In PyTorch one needs to define which device to use for computation. All tensors involved in the computation need to be on that device. The most common devices are:\n",
        "- `cpu`: any of your computer's CPUs\n",
        "- `cpu:0`:the first of your computer's CPUs\n",
        "- `cuda`: any of your computer's GPUs\n",
        "- `cuda:2`: the third GPU of you computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9HxsXGisi9T",
        "outputId": "0d0602e6-ac46-42e9-96f6-a7b9b608e7ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# get gpu if available else cpu:\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qs-4FS3uKsMZ"
      },
      "outputs": [],
      "source": [
        "# move a model or tensor to the device:\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZAZKxtFBFR"
      },
      "source": [
        "Prediction on new instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdDh74y0i7fX",
        "outputId": "6c1cc53f-c0e7-4e6c-98d2-9c3d7a2a6cb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09265865, 0.0770546 , 0.09043783, 0.09605167, 0.11902986,\n",
              "        0.10232511, 0.09455788, 0.11377003, 0.09934575, 0.11476856],\n",
              "       [0.11936605, 0.08061998, 0.08598896, 0.09390613, 0.12003439,\n",
              "        0.10104395, 0.07934042, 0.1247673 , 0.08428048, 0.11065232],\n",
              "       [0.10060699, 0.08490358, 0.09437028, 0.09809183, 0.10922495,\n",
              "        0.10153415, 0.0844824 , 0.10817386, 0.09265278, 0.12595919]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "X_new = pt.tensor(X_test[:3], dtype=pt.float32, device=device)\n",
        "y_proba = model(X_new) # this returns a probability?\n",
        "y_proba = y_proba.detach().cpu().numpy() # to numpy\n",
        "y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU8cAN3fi99y",
        "outputId": "1a761807-ac2d-4cc2-e808-d13a319c4c93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Coat', 'Sneaker', 'Ankle boot'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "np.array(class_names)[np.argmax(y_proba, axis=1)] #if we want to know the class names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9wLOuG8vK_r"
      },
      "source": [
        "Instances of `torch.nn.Module` have a method `.train()` and a method `.eval()` that set the whole module (including submodules) in a training or prediction mode.\n",
        "\n",
        "This is necessary, as for example dropout layers are inactive during prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIRxMYLRqnoU"
      },
      "source": [
        "In order to train the network, we need to define a training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "FqjxNg_mDP2z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "aBxz4ZXkz4hT"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  # 1. set model to train:\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      # move tensors to correct device:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      # reset all gradients to zero:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # create predictions:\n",
        "      y_pred = model(X_batch)\n",
        "\n",
        "      # calculate loss:\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "      # backpropagate loss:\n",
        "      loss.backward()\n",
        "\n",
        "      # update weights:\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "adSjw6i50L3b"
      },
      "outputs": [],
      "source": [
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  # 1. set model to eval:\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    # move tensors to correct device:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # create predictions:\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    # calculate loss:\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "  # calculate f1 score:\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SASZ5PCXq4tr"
      },
      "outputs": [],
      "source": [
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float):\n",
        "  # instantiate optimizer:\n",
        "  optimizer = pt.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  # instantiate loss function:\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "    # train for one epoch:\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "\n",
        "    # evaluate on validation:\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    # save metrics:\n",
        "    history.append({\n",
        "      'loss_train':loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1']\n",
        "    })\n",
        "\n",
        "    # print message:\n",
        "    print(f'Epoch {i+1:d}/{epochs:d}:', *[f'{metric} = {history[-1][metric]:.2f};' for metric in history[-1]], sep='\\t')\n",
        "\n",
        "  # return history:\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08uZrmWMCmq"
      },
      "source": [
        "Fit the model for 30 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "U1VqXewrMCVQ",
        "outputId": "59817c6b-fa62-4cac-c79a-25f736c47f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\tloss_train = 2.29;\tloss_valid = 2.27;\tf1_valid = 0.20;\n",
            "Epoch 2/30:\tloss_train = 2.17;\tloss_valid = 2.02;\tf1_valid = 0.34;\n",
            "Epoch 3/30:\tloss_train = 1.95;\tloss_valid = 1.89;\tf1_valid = 0.48;\n",
            "Epoch 4/30:\tloss_train = 1.88;\tloss_valid = 1.85;\tf1_valid = 0.52;\n",
            "Epoch 5/30:\tloss_train = 1.82;\tloss_valid = 1.78;\tf1_valid = 0.66;\n",
            "Epoch 6/30:\tloss_train = 1.78;\tloss_valid = 1.74;\tf1_valid = 0.69;\n",
            "Epoch 7/30:\tloss_train = 1.75;\tloss_valid = 1.72;\tf1_valid = 0.69;\n",
            "Epoch 8/30:\tloss_train = 1.73;\tloss_valid = 1.71;\tf1_valid = 0.77;\n",
            "Epoch 9/30:\tloss_train = 1.71;\tloss_valid = 1.69;\tf1_valid = 0.79;\n",
            "Epoch 10/30:\tloss_train = 1.70;\tloss_valid = 1.69;\tf1_valid = 0.73;\n",
            "Epoch 11/30:\tloss_train = 1.70;\tloss_valid = 1.68;\tf1_valid = 0.79;\n",
            "Epoch 12/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.72;\n",
            "Epoch 13/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.72;\n",
            "Epoch 14/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.77;\n",
            "Epoch 15/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.77;\n",
            "Epoch 16/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.76;\n",
            "Epoch 17/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.79;\n",
            "Epoch 18/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.76;\n",
            "Epoch 19/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 20/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 21/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 22/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 23/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 24/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 25/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 26/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 27/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.72;\n",
            "Epoch 28/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
            "Epoch 29/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.77;\n",
            "Epoch 30/30:\tloss_train = 1.65;\tloss_valid = 1.65;\tf1_valid = 0.74;\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='epoch', ylabel='loss'>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# instantiate model and move to device:\n",
        "model = CustomNetwork().to(device)\n",
        "\n",
        "# train model:\n",
        "history = fit(model, loader_train, loader_valid, epochs=30, lr=.01)\n",
        "\n",
        "# plot history:\n",
        "history[['loss_train', 'loss_valid']].plot(xlabel='epoch', ylabel='loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qmHUt5M_nQd"
      },
      "source": [
        "**Evaluation**: `evaluate` will return the metric scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdArSMDi8BI",
        "outputId": "f889577f-697e-475f-82c4-ddabd6b6f5dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "evaluate(model, loader_test) #evaluate on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSUB0uJTPBg"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 4</b> - Improved Training:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Improve the above training loop with the following steps:\n",
        "1. replace the very basic SGD optimizer with the momentum-based [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer. Compare how the learning curves change after this step. **As ADAM is more sensitive to the learning rate, set it to `0.001` after changing the optimizer!**\n",
        "2. add a [`torch.optim.lr_scheduler.LinearLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html) scheduler (_start: `1.0*lr`, end:`0.33*lr`, over 10 epochs_).  Compare how the learning curves change after this step.\n",
        "3. add an **early stopping** functionality, that stops training when the validation loss has not improved for `patience` epochs and restores the model parameters to the ones achieving the best loss. **Use a patience of `5` to retrain the network.**\n",
        "\n",
        "**Disclaimer:** *We will not check whether you actually compare the loss curves before and after adding a specific step. But we may ask about their impact in the final exam.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9sPm0Newq4rH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pwOaMCDSTOpS"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(X_batch)\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)\n",
        "\n",
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}\n",
        "\n",
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float, patience:int):\n",
        "  optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
        "  scheduler = pt.optim.lr_scheduler.LinearLR(\n",
        "        optimizer,\n",
        "        start_factor=1.0,\n",
        "        end_factor=0.33,\n",
        "        total_iters=10\n",
        "    )\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  best_loss = float('inf')\n",
        "  best_state_dict = None\n",
        "  no_improvement_epochs = 0\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "        loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "        metrics = evaluate(model, loader_valid, loss_fn)\n",
        "        scheduler.step()\n",
        "        current_val_loss = metrics['loss'] #validation loss\n",
        "        if current_val_loss < best_loss:\n",
        "            best_loss = current_val_loss\n",
        "            best_state_dict = model.state_dict()\n",
        "            no_improvement_epochs = 0\n",
        "        else:\n",
        "            no_improvement_epochs += 1\n",
        "\n",
        "        history.append({\n",
        "            'loss_train': loss_train,\n",
        "            'loss_valid': metrics['loss'],\n",
        "            'f1_valid': metrics['f1']\n",
        "        })\n",
        "\n",
        "        if no_improvement_epochs >= patience:\n",
        "          model.load_state_dict(best_state_dict)\n",
        "          break\n",
        "\n",
        "  return pd.DataFrame(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-hDPkRUY0R"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 4. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKm2rIvKUP2C"
      },
      "source": [
        "### Section 4: Other useful and frequently used functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4BHXYqUWBH"
      },
      "source": [
        "Save and load the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBmnCPTdaAlV"
      },
      "source": [
        "**Option 1:** `torch.save(...)` / `torch.load(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QQIhSX16UXpR"
      },
      "outputs": [],
      "source": [
        "pt.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrmRkkvbVYqj",
        "outputId": "7df68208-9c3c-458f-ce5e-f679fe32d8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  model.pt\n",
            " extracting: model/data.pkl          \n",
            " extracting: model/byteorder         \n",
            " extracting: model/data/0            \n",
            " extracting: model/data/1            \n",
            " extracting: model/data/2            \n",
            " extracting: model/data/3            \n",
            " extracting: model/data/4            \n",
            " extracting: model/data/5            \n",
            " extracting: model/version           \n",
            " extracting: model/.data/serialization_id  \n"
          ]
        }
      ],
      "source": [
        "# this saves a zipfile!\n",
        "!unzip model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexXOBTKUZH_",
        "outputId": "4f8c8489-7fc0-4327-c3ff-23a4d3be4a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = pt.load('model.pt', weights_only=False) # \"weights_only = True\" only loads PyTorch Tensors in the model file!\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr88yK-8Z5GY"
      },
      "source": [
        "**Option 2:** save/load state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "FsXhrkFhZ9NY"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "44MB9qujUPys"
      },
      "outputs": [],
      "source": [
        "with open('model_state_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(model.state_dict(), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CuVaeSJZgW0",
        "outputId": "39c3a9bc-46b0-4f3d-8d87-c4f8eb42a847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "with open('model_state_dict.pkl', 'rb') as f:\n",
        "  state_dict = pickle.load(f)\n",
        "model.load_state_dict(state_dict)\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w003CKN5R7vY"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 5</b> - Regression MLP</span>\n",
        "\n",
        "---\n",
        "\n",
        "We have created a classification model on Fashion MNIST with PyTorch. In addition, we can of course use similar PyTorch models to solve regression tasks. **How can we do that?** Which part should we change to make it work on regression tasks? That would be our last task in this lab. Based on your knowledge from the second lecture, you may be able to figure out which part you need to change.\n",
        "\n",
        "Create a regression model by adapting the PyTorch model we used above and train it on the [california housing dataset](https://nextilearn.dsv.su.se/mod/resource/view.php?id=25386 ).\n",
        "You may need to change **a loss function** and input / output layers as we no longer deal with images and classification. Feel free to use scikit-learn but we still recommend you to practice preprocessing with NumPy for your skills.\n",
        "\n",
        "**Upload the resulting predictions to NextIlearn. Your model should achieve an MSE < XXX to pass.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qforG1NGbEuq"
      },
      "source": [
        "1. Get training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpmUlavla3Py",
        "outputId": "13b58bea-2909-494a-95d3-83c9afea469d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['description.md', 'labels_train.csv', 'data_train.csv', 'data_test.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# 1.1 download https://www.google.com/url?q=https%3A%2F%2Fnextilearn.dsv.su.se%2Fmod%2Fresource%2Fview.php%3Fid%3D25386 to data.zip\n",
        "\n",
        "# 1.2 unzip data.zip\n",
        "import zipfile,os\n",
        "\n",
        "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "\n",
        "#!unzip data.zip\n",
        "\n",
        "# 1.3 check files:\n",
        "os.listdir('data/task5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYglS3ybCM8"
      },
      "source": [
        "2. Create Data Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "NQ_Rj925R7vY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91af35c7-d266-4902-f22d-f66e5ac4908c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  4.3036      36.0  5.065630   1.069085      1115.0  1.925734     34.15   \n",
            "1  2.9085      21.0  3.962923   1.102508      1985.0  2.164667     36.60   \n",
            "2  4.1378      24.0  4.582307   1.000000      2819.0  3.156775     33.83   \n",
            "3  4.5625      34.0  5.764120   1.056478      1019.0  3.385382     37.36   \n",
            "4  4.3462      36.0  5.919492   1.108051      1334.0  2.826271     34.22   \n",
            "\n",
            "   Longitude  \n",
            "0    -118.38  \n",
            "1    -121.86  \n",
            "2    -118.29  \n",
            "3    -121.98  \n",
            "4    -118.51  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# 2.1 load training data:\n",
        "data_train = pd.read_csv('data/task5/data_train.csv', index_col=0)\n",
        "labels_train = pd.read_csv('data/task5/labels_train.csv', index_col=0)\n",
        "\n",
        "# 2.2 load test data (no labels):\n",
        "data_test = pd.read_csv('data/task5/data_test.csv', index_col=0)\n",
        "\n",
        "#...\n",
        "#print(data_train.head())\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(data_train)\n",
        "X_test_scaled = scaler.transform(data_test)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_scaled, labels_train.values.ravel(), test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = TensorDataset(pt.tensor(X_train, dtype=pt.float32), pt.tensor(y_train, dtype=pt.float32))\n",
        "valid_dataset = TensorDataset(pt.tensor(X_valid, dtype=pt.float32), pt.tensor(y_valid, dtype=pt.float32))\n",
        "loader_train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "loader_valid = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRz2hDYbYJ6"
      },
      "source": [
        "3. Create Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nl0-sMfCR7vZ"
      },
      "outputs": [],
      "source": [
        "#...\n",
        "class RegressionNetwork(nn.Module):\n",
        "    def __init__(self, input_dim: int):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 128)\n",
        "        self.layer2 = nn.Linear(128, 64)\n",
        "        self.output_layer = nn.Linear(64, 1)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))  #\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.output_layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSyLqesbkYc"
      },
      "source": [
        "4. Train model on `data_train` and `labels_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "_dqM_Yzyb1ho"
      },
      "outputs": [],
      "source": [
        "#...\n",
        "def epoch_func(model, loader_train, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    losses = []  # Store batch losses\n",
        "    for X_batch, y_batch in loader_train:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        y_pred = model(X_batch)  # Forward pass\n",
        "        loss = loss_fn(y_pred, y_batch)  # Compute loss\n",
        "        losses.append(loss.item())  # Store loss value\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "    return np.mean(losses)  # Return average training loss\n",
        "def evaluate_func(model, loader_valid, loss_fn):\n",
        "    model.eval()\n",
        "    losses = []  # Store batch losses\n",
        "    predictions = []  # Store predictions\n",
        "    with pt.no_grad():\n",
        "      for X_batch, y_batch in loader_valid:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
        "        y_pred = model(X_batch)  # Forward pass\n",
        "        loss = loss_fn(y_pred, y_batch)  # Compute loss\n",
        "        losses.append(loss.item())  # Store loss value\n",
        "        predictions.extend(y_pred.cpu().numpy())  # Store predictions\n",
        "\n",
        "    return {'loss': np.mean(losses), 'predictions': predictions}  # Return average validation loss and predictions\n",
        "\n",
        "def fit_func(model, loader_train, loader_valid, epochs, lr, patience):\n",
        "    optimizer = pt.optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n",
        "    scheduler = pt.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.33, total_iters=10)  # Learning rate scheduler\n",
        "    loss_fn = pt.nn.MSELoss()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_state_dict = None\n",
        "    no_improvement_epochs = 0\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = epoch_func(model, loader_train, optimizer, loss_fn)\n",
        "        metrics = evaluate_func(model, loader_valid, loss_fn)\n",
        "        scheduler.step()\n",
        "        val_loss = metrics['loss'] #validationloss\n",
        "        # Early stopping logic\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_state_dict = model.state_dict()\n",
        "            no_improvement_epochs = 0\n",
        "        else:\n",
        "            no_improvement_epochs += 1\n",
        "\n",
        "\n",
        "        history.append({'train_loss': train_loss, 'val_loss': val_loss})\n",
        "\n",
        "        if no_improvement_epochs >= patience:\n",
        "          model.load_state_dict(best_state_dict)\n",
        "          break\n",
        "\n",
        "    return pd.DataFrame(history)\n",
        "\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "model = RegressionNetwork(input_dim=X_train.shape[1]).to(device)\n",
        "history = fit_func(model, loader_train, loader_valid, epochs=30, lr=0.001, patience=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipIi84zb5ZR"
      },
      "source": [
        "5. Predict `data_test` and save predictions to `submission.csv`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "V_gqdJvucm2l"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with pt.no_grad():\n",
        "  X_test_tensor = pt.tensor(X_test_scaled, dtype=pt.float32).to(device)\n",
        "  predictions = model(X_test_tensor)\n",
        "\n",
        "pd.DataFrame(predictions.detach().cpu().numpy(), columns=['predictions']).to_csv('submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB-ezFJER7vZ"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 5. Upload your final predictions (the file* `submission.csv` *) to **Homework 2 - Code** on **NextIlearn***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}